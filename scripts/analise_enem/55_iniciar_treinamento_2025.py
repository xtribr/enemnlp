#!/usr/bin/env python3
"""
üöÄ Iniciar Treinamento/Avalia√ß√£o ENEM 2025
===========================================

Este script inicia a avalia√ß√£o das 180 quest√µes do ENEM 2025 usando Maritaca Sabi√°-3.

Uso:
    python 55_iniciar_treinamento_2025.py [--area todas|linguagens|humanas|natureza|matematica] [--limit N]
"""

import os
import sys
import json
import time
import argparse
from datetime import datetime
from pathlib import Path
from typing import Dict, List
from collections import defaultdict

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    import openai
except ImportError:
    print("‚ùå Erro: openai n√£o instalado")
    print("   Execute: pip install openai")
    sys.exit(1)

# =============================================================================
# CONFIGURA√á√ïES
# =============================================================================

PROMPT_COT_IMPROVED = """Voc√™ √© um especialista em resolu√ß√£o de quest√µes do ENEM. Sua tarefa √© analisar a quest√£o de m√∫ltipla escolha abaixo, elaborar uma explica√ß√£o passo-a-passo detalhada e, por fim, indicar a alternativa correta.

Siga rigorosamente os passos abaixo:
1. **Leitura Atenta e Compreens√£o do Enunciado:** Leia a quest√£o completa, incluindo textos de apoio, gr√°ficos, tabelas ou figuras. Identifique o que est√° sendo pedido e quais s√£o as informa√ß√µes fornecidas.
2. **Identifica√ß√£o do Tipo de Problema:** Classifique a quest√£o em uma √°rea do conhecimento e identifique os conceitos envolvidos.
3. **Extra√ß√£o de Dados Relevantes:** Liste todos os dados num√©ricos e informa√ß√µes cruciais presentes no enunciado, figuras ou tabelas.
4. **Defini√ß√£o da Estrat√©gia de Resolu√ß√£o:** Descreva o plano de ataque para resolver o problema.
5. **C√°lculos e Desenvolvimento:** Execute os c√°lculos passo a passo, mostrando claramente cada etapa.
6. **Verifica√ß√£o e Valida√ß√£o:** Revise os c√°lculos e o racioc√≠nio.
7. **Compara√ß√£o com Alternativas:** Compare o resultado obtido com as alternativas fornecidas.
8. **Resposta Final:** Indique a alternativa correta.

Apenas uma alternativa √© correta. Encerre a explica√ß√£o com "Resposta: " seguido pela alternativa."""

# =============================================================================
# FUN√á√ïES AUXILIARES
# =============================================================================

def setup_api():
    """Configura a API da Maritaca."""
    api_key = os.environ.get('CURSORMINIMAC') or os.environ.get('MARITALK_API_SECRET_KEY')
    
    if not api_key:
        print("‚ùå Erro: Chave API n√£o encontrada")
        print("   Configure CURSORMINIMAC ou MARITALK_API_SECRET_KEY")
        sys.exit(1)
    
    # Detectar vers√£o do openai
    openai_version = int(openai.__version__.split('.')[0])
    
    if openai_version >= 1:
        client = openai.OpenAI(
            api_key=api_key,
            base_url="https://chat.maritaca.ai/api"
        )
        return client, "new"
    else:
        openai.api_key = api_key
        openai.api_base = "https://chat.maritaca.ai/api"
        return None, "old"

def extract_answer(response_text):
    """Extrai a resposta (A, B, C, D ou E) do texto do modelo."""
    import re
    patterns = [
        r'[Rr]esposta:\s*([A-Ea-e])',
        r'[Rr]esposta:\s*\(?([A-Ea-e])\)?',
        r'[Aa]lternativa:\s*([A-Ea-e])',
        r'\b([A-Ea-e])\s*[.)\]]?\s*$',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, response_text)
        if match:
            return match.group(1).upper()
    
    letters = re.findall(r'\b([A-Ea-e])[.)\]]?\b', response_text)
    if letters:
        return letters[-1].upper()
    
    return None

def call_model(client, api_type, messages, max_retries=3):
    """Chama o modelo com retry."""
    for attempt in range(max_retries):
        try:
            if api_type == "new":
                response = client.chat.completions.create(
                    model="sabia-3",
                    messages=messages,
                    max_tokens=1500,
                    temperature=0.1
                )
                return response.choices[0].message.content
            else:
                response = openai.ChatCompletion.create(
                    model="sabia-3",
                    messages=messages,
                    max_tokens=1500,
                    temperature=0.1
                )
                return response.choices[0].message.content
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Tentativa {attempt + 1} falhou: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
            else:
                return None
    return None

def build_messages(question_data):
    """Constr√≥i as mensagens para o modelo."""
    messages = [{"role": "system", "content": PROMPT_COT_IMPROVED}]
    
    # Construir a quest√£o
    question_text = question_data.get('question', '')
    context = question_data.get('context', '')
    
    if context:
        question_text = f"{context}\n\n{question_text}" if question_text else context
    
    # Adicionar descri√ß√£o de imagem se houver
    if question_data.get('image_description'):
        question_text += f"\n\n[Descri√ß√£o da imagem]: {question_data['image_description']}"
    
    # Formatar alternativas
    alternatives = question_data.get('alternatives', [])
    alt_text = ""
    for i, alt in enumerate(alternatives):
        if alt and alt.strip():
            letter = chr(65 + i)  # A, B, C, D, E
            alt_text += f"{letter}. {alt}\n"
    
    user_msg = f"Quest√£o: {question_text}\n\nAlternativas:\n{alt_text}"
    messages.append({"role": "user", "content": user_msg})
    
    return messages

def load_questions_2025(area: str = "todas"):
    """Carrega quest√µes do ENEM 2025."""
    project_root = Path(__file__).parent.parent.parent
    processed_dir = project_root / "data" / "processed"
    
    if area == "todas":
        arquivo = processed_dir / "enem_2025_completo.jsonl"
    else:
        area_map = {
            'linguagens': 'languages',
            'humanas': 'human-sciences',
            'natureza': 'natural-sciences',
            'matematica': 'mathematics'
        }
        area_norm = area_map.get(area.lower(), area)
        arquivo = processed_dir / f"enem_2025_{area_norm}.jsonl"
    
    if not arquivo.exists():
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo}")
        print("   Execute primeiro: python 54_integrar_todas_questoes_2025.py")
        sys.exit(1)
    
    questions = []
    with open(arquivo, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                q = json.loads(line)
                # Filtrar por √°rea se necess√°rio
                if area != "todas":
                    area_map = {
                        'linguagens': 'languages',
                        'humanas': 'human-sciences',
                        'natureza': 'natural-sciences',
                        'matematica': 'mathematics'
                    }
                    area_norm = area_map.get(area.lower(), area)
                    if q.get('area') != area_norm:
                        continue
                # Filtrar quest√µes sem label v√°lido
                if not q.get('label') or q.get('label') == 'ANULADO':
                    continue
                questions.append(q)
    
    return questions

def main():
    parser = argparse.ArgumentParser(description="Avalia√ß√£o ENEM 2025 com Maritaca")
    parser.add_argument("--area", type=str, default="todas",
                       help="√Årea para avaliar (todas, linguagens, humanas, natureza, matematica)")
    parser.add_argument("--limit", type=int, default=None,
                       help="N√∫mero m√°ximo de quest√µes para avaliar (para testes)")
    args = parser.parse_args()
    
    print("=" * 70)
    print("üöÄ INICIANDO TREINAMENTO/AVALIA√á√ÉO - ENEM 2025")
    print("=" * 70)
    print()
    
    # Configurar API
    print("üîß Configurando API...")
    client, api_type = setup_api()
    print("‚úÖ API configurada")
    
    # Carregar quest√µes
    print(f"\nüì• Carregando quest√µes de {args.area.upper()}...")
    questions = load_questions_2025(args.area)
    
    if args.limit:
        questions = questions[:args.limit]
    
    print(f"‚úÖ {len(questions)} quest√µes carregadas")
    
    if not questions:
        print("‚ùå Nenhuma quest√£o para avaliar")
        sys.exit(1)
    
    # Estat√≠sticas iniciais
    print("\nüìä Estat√≠sticas das Quest√µes:")
    stats = defaultdict(int)
    for q in questions:
        stats[q.get('area', 'unknown')] += 1
    for area, count in sorted(stats.items()):
        print(f"  {area}: {count} quest√µes")
    
    # Iniciar avalia√ß√£o
    print(f"\nüéØ Iniciando avalia√ß√£o de {len(questions)} quest√µes...")
    print()
    
    results = []
    correct_count = 0
    start_time = time.time()
    
    for i, question_data in enumerate(questions):
        q_id = question_data.get('id', 'unknown')
        q_num = question_data.get('number', 'unknown')
        correct_label = question_data.get('label', '').upper()
        area = question_data.get('area', 'unknown')
        
        print(f"[{i+1}/{len(questions)}] Quest√£o {q_num} ({area}) - ID: {q_id}")
        
        # Construir mensagens
        messages = build_messages(question_data)
        
        # Chamar modelo
        model_response = call_model(client, api_type, messages)
        
        if model_response:
            model_answer = extract_answer(model_response)
            is_correct = (model_answer == correct_label) if model_answer else False
            
            if is_correct:
                correct_count += 1
                status = "‚úÖ"
            else:
                status = "‚ùå"
            
            print(f"  {status} Esperado: {correct_label}, Modelo: {model_answer or 'N/A'}")
            
            results.append({
                'id': q_id,
                'number': q_num,
                'area': area,
                'correct_label': correct_label,
                'model_answer': model_answer,
                'model_response_raw': model_response[:200] + "..." if len(model_response) > 200 else model_response,
                'correto': is_correct,
                'has_images': question_data.get('has_images', False)
            })
        else:
            print(f"  ‚ö†Ô∏è  Erro ao obter resposta do modelo")
            results.append({
                'id': q_id,
                'number': q_num,
                'area': area,
                'correct_label': correct_label,
                'model_answer': None,
                'model_response_raw': None,
                'correto': False,
                'has_images': question_data.get('has_images', False)
            })
        
        # Mostrar progresso
        accuracy = (correct_count / (i + 1)) * 100
        elapsed = time.time() - start_time
        avg_time = elapsed / (i + 1)
        remaining = avg_time * (len(questions) - i - 1)
        
        print(f"  Progresso: {accuracy:.1f}% | Tempo: {elapsed:.0f}s | Restante: ~{remaining:.0f}s")
        print()
        
        # Pequena pausa para n√£o sobrecarregar a API
        time.sleep(0.5)
    
    # Calcular estat√≠sticas finais
    final_accuracy = (correct_count / len(questions)) * 100 if questions else 0
    total_time = time.time() - start_time
    
    # Estat√≠sticas por √°rea
    area_stats = defaultdict(lambda: {'correct': 0, 'total': 0})
    for r in results:
        area = r['area']
        area_stats[area]['total'] += 1
        if r['correto']:
            area_stats[area]['correct'] += 1
    
    # Salvar resultados
    output_dir = Path("results")
    output_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"avaliacao_enem_2025_{args.area}_{timestamp}.json"
    
    output_data = {
        'timestamp': timestamp,
        'area': args.area,
        'total_questions': len(questions),
        'correct_answers': correct_count,
        'accuracy': final_accuracy,
        'total_time_seconds': total_time,
        'area_stats': {
            area: {
                'total': stats['total'],
                'correct': stats['correct'],
                'accuracy': (stats['correct'] / stats['total'] * 100) if stats['total'] > 0 else 0
            }
            for area, stats in area_stats.items()
        },
        'results': results
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    # Mostrar resultados
    print("=" * 70)
    print("üìä RESULTADOS FINAIS")
    print("=" * 70)
    print()
    print(f"Total de quest√µes: {len(questions)}")
    print(f"Acertos: {correct_count}")
    print(f"Acur√°cia geral: {final_accuracy:.2f}%")
    print(f"Tempo total: {total_time:.1f} segundos")
    print(f"Tempo m√©dio por quest√£o: {total_time/len(questions):.1f} segundos")
    print()
    
    print("üìä Por √Årea:")
    for area in sorted(area_stats.keys()):
        stats = area_stats[area]
        acc = (stats['correct'] / stats['total'] * 100) if stats['total'] > 0 else 0
        print(f"  {area:20s}: {stats['correct']:3d}/{stats['total']:3d} = {acc:5.1f}%")
    
    print()
    print(f"üíæ Resultados salvos em: {output_file}")
    print()
    print("=" * 70)
    print("‚úÖ AVALIA√á√ÉO CONCLU√çDA")
    print("=" * 70)

if __name__ == "__main__":
    main()

