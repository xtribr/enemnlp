# ğŸš€ Guia: Usar GPT-4-ENEM no Google Colab com GPU

Este guia explica como configurar e usar o projeto GPT-4-ENEM no Google Colab para aproveitar GPUs como A100, T4, V100, etc.

---

## ğŸ“‹ Ãndice

1. [Por que usar Google Colab?](#por-que-usar-google-colab)
2. [ConfiguraÃ§Ã£o Inicial](#configuraÃ§Ã£o-inicial)
3. [Usando o Notebook](#usando-o-notebook)
4. [Alternativas: Upload Manual](#alternativas-upload-manual)
5. [Dicas e Troubleshooting](#dicas-e-troubleshooting)

---

## ğŸ¯ Por que usar Google Colab?

### Vantagens:
- âœ… **GPU gratuita** (T4) ou A100 com Colab Pro
- âœ… **Ambiente prÃ©-configurado** (Python, CUDA, etc.)
- âœ… **Sem instalaÃ§Ã£o local** necessÃ¡ria
- âœ… **FÃ¡cil compartilhamento** de notebooks
- âœ… **Armazenamento temporÃ¡rio** para dados e resultados

### LimitaÃ§Ãµes:
- âš ï¸ SessÃµes tÃªm tempo limite (12h gratuito, 24h Pro)
- âš ï¸ GPU pode nÃ£o estar sempre disponÃ­vel (gratuito)
- âš ï¸ Dados sÃ£o temporÃ¡rios (faÃ§a backup!)

---

## ğŸš€ ConfiguraÃ§Ã£o Inicial

### Passo 1: Acessar Google Colab

1. Acesse: https://colab.research.google.com/
2. FaÃ§a login com sua conta Google
3. Crie um novo notebook ou abra um existente

### Passo 2: Configurar GPU

1. VÃ¡ em **Runtime â†’ Change runtime type**
2. Em **Hardware accelerator**, selecione **GPU**
3. Para A100, vocÃª precisa de **Colab Pro** ou **Colab Pro+**
4. Clique em **Save**

### Passo 3: Abrir Notebook

**OpÃ§Ã£o A: Usar notebook prÃ©-configurado**
- Abra `notebooks/gpt4_enem_colab_setup.ipynb` no Colab
- Ou faÃ§a upload do arquivo `.ipynb`

**OpÃ§Ã£o B: Criar do zero**
- Siga as instruÃ§Ãµes abaixo

---

## ğŸ““ Usando o Notebook

### Estrutura do Notebook

O notebook `gpt4_enem_colab_setup.ipynb` contÃ©m:

1. **VerificaÃ§Ã£o de GPU** - Confirma se GPU estÃ¡ ativa
2. **InstalaÃ§Ã£o de DependÃªncias** - Instala todos os pacotes necessÃ¡rios
3. **Clone do RepositÃ³rio** - Baixa o cÃ³digo do GitHub
4. **ConfiguraÃ§Ã£o de API** - Configura chaves da Maritaca/OpenAI
5. **Teste de ConexÃ£o** - Verifica se API estÃ¡ funcionando
6. **ExecuÃ§Ã£o de AvaliaÃ§Ãµes** - Roda avaliaÃ§Ãµes do ENEM
7. **AnÃ¡lise de Resultados** - Visualiza e analisa resultados

### Executando CÃ©lulas

1. Execute cada cÃ©lula na ordem (Shift+Enter)
2. Aguarde instalaÃ§Ãµes completarem
3. Configure sua chave API antes de testar conexÃ£o

---

## ğŸ”§ Alternativas: Upload Manual

Se preferir nÃ£o clonar do GitHub:

### Passo 1: Preparar Arquivos

No seu computador local:

```bash
# Criar arquivo ZIP do projeto (sem dados grandes)
zip -r gpt4-enem-colab.zip . \
    -x "*.git*" \
    -x "data/figures/*" \
    -x "lm_cache/*" \
    -x "*.pyc" \
    -x "__pycache__/*"
```

### Passo 2: Upload no Colab

1. No Colab, vÃ¡ em **Files â†’ Upload**
2. Selecione o arquivo ZIP
3. Descompacte:
   ```python
   !unzip gpt4-enem-colab.zip
   ```

### Passo 3: Instalar DependÃªncias

Siga as cÃ©lulas do notebook para instalar tudo.

---

## âš™ï¸ ConfiguraÃ§Ã£o Detalhada

### 1. Verificar GPU

```python
import torch
print(f"GPU: {torch.cuda.get_device_name(0)}")
print(f"MemÃ³ria: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
```

### 2. Instalar DependÃªncias

```python
# Instalar PyTorch com CUDA
!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Instalar dependÃªncias do projeto
!pip install -q transformers datasets scikit-learn
!pip install -q sqlitedict pytablewriter sacrebleu rouge-score
!pip install -q openai fschat

# Instalar projeto
!git clone https://github.com/piresramon/gpt-4-enem.git
%cd gpt-4-enem
!pip install -e .
```

### 3. Configurar API

```python
import os

# Sua chave API da Maritaca
os.environ['CURSORMINIMAC'] = 'sua-chave-aqui'

# Ou
os.environ['MARITALK_API_SECRET_KEY'] = 'sua-chave-aqui'
```

### 4. Testar ConexÃ£o

```python
import openai

api_key = os.environ.get('CURSORMINIMAC')
openai.api_base = "https://chat.maritaca.ai/api"

# Para openai >= 1.0
client = openai.OpenAI(api_key=api_key, base_url="https://chat.maritaca.ai/api")
response = client.chat.completions.create(
    model="sabia-3",
    messages=[{"role": "user", "content": "OK"}],
    max_tokens=5
)
print(response.choices[0].message.content)
```

### 5. Executar AvaliaÃ§Ã£o

```python
!python main.py \
    --model maritalk \
    --model_args engine=sabia-3 \
    --tasks enem_cot_2024_blind \
    --description_dict_path description.json \
    --num_fewshot 3 \
    --conversation_template chatgpt \
    --limit 10 \
    --output_path results/teste.json
```

---

## ğŸ’¡ Dicas e Troubleshooting

### GPU nÃ£o disponÃ­vel?

**Problema**: "GPU nÃ£o detectada"

**SoluÃ§Ãµes**:
1. Verifique se ativou GPU em Runtime â†’ Change runtime type
2. Para A100, vocÃª precisa de Colab Pro
3. Tente desconectar e reconectar (Runtime â†’ Disconnect and delete runtime)

### Erro de memÃ³ria?

**Problema**: "Out of memory"

**SoluÃ§Ãµes**:
1. Use `--limit` para testar com menos questÃµes
2. Feche outras abas do Colab
3. Reinicie o runtime (Runtime â†’ Restart runtime)

### API nÃ£o funciona?

**Problema**: "Authentication error"

**SoluÃ§Ãµes**:
1. Verifique se a chave estÃ¡ correta
2. Confirme que configurou a variÃ¡vel de ambiente
3. Teste a chave localmente primeiro

### Dados nÃ£o encontrados?

**Problema**: "File not found: data/enem/2024.jsonl"

**SoluÃ§Ãµes**:
1. Os dados sÃ£o baixados automaticamente na primeira execuÃ§Ã£o
2. Ou faÃ§a upload manual dos arquivos `.jsonl`
3. Verifique o caminho do diretÃ³rio

### SessÃ£o expirada?

**Problema**: "Runtime disconnected"

**SoluÃ§Ãµes**:
1. FaÃ§a download dos resultados regularmente
2. Use `--output_path` para salvar resultados
3. Colab Pro tem sessÃµes mais longas (24h)

---

## ğŸ“Š Exemplo Completo

```python
# 1. Setup
import os
os.environ['CURSORMINIMAC'] = 'sua-chave'

# 2. Executar avaliaÃ§Ã£o
!python main.py \
    --model maritalk \
    --model_args engine=sabia-3 \
    --tasks enem_cot_2024_blind \
    --description_dict_path description.json \
    --num_fewshot 3 \
    --conversation_template chatgpt \
    --limit 5 \
    --output_path results/teste.json

# 3. Analisar resultados
import json
with open('results/teste.json') as f:
    results = json.load(f)
print(json.dumps(results, indent=2, ensure_ascii=False))
```

---

## ğŸ”„ Workflow Recomendado

1. **Abrir Colab** â†’ Criar novo notebook
2. **Configurar GPU** â†’ Runtime â†’ Change runtime type â†’ GPU
3. **Executar setup** â†’ Rodar cÃ©lulas de instalaÃ§Ã£o
4. **Configurar API** â†’ Adicionar sua chave
5. **Testar** â†’ Rodar avaliaÃ§Ã£o com `--limit 5`
6. **Avaliar completo** â†’ Remover `--limit` para avaliaÃ§Ã£o completa
7. **Download** â†’ Baixar resultados antes de desconectar

---

## ğŸ“¦ Estrutura de Arquivos no Colab

```
/content/
â”œâ”€â”€ gpt-4-enem/          # Projeto clonado
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ enem/        # Dados ENEM
â”‚   â”œâ”€â”€ lm_eval/         # CÃ³digo de avaliaÃ§Ã£o
â”‚   â”œâ”€â”€ main.py          # Script principal
â”‚   â””â”€â”€ ...
â”œâ”€â”€ results/              # Resultados (criar manualmente)
â”‚   â””â”€â”€ *.json           # Arquivos de resultados
â””â”€â”€ ...
```

---

## ğŸ“ Casos de Uso

### 1. Teste RÃ¡pido
```bash
--limit 5  # Apenas 5 questÃµes
```

### 2. AvaliaÃ§Ã£o Completa
```bash
# Sem --limit, todas as questÃµes
```

### 3. MÃºltiplas Tarefas
```bash
--tasks enem_cot_2024_blind,enem_cot_2024_captions
```

### 4. ComparaÃ§Ã£o de Modelos
```bash
# Executar com diferentes --model_args
```

---

## âš ï¸ Importante

1. **Dados sÃ£o temporÃ¡rios** - FaÃ§a download regularmente
2. **Custos de API** - Monitore uso da API Maritaca
3. **Tempo de sessÃ£o** - SessÃµes expiram (12h/24h)
4. **GPU nÃ£o Ã© necessÃ¡ria** - API Maritaca Ã© remota, mas Colab oferece ambiente estÃ¡vel

---

## ğŸ“ Suporte

- **DocumentaÃ§Ã£o**: `docs/`
- **Notebook**: `notebooks/gpt4_enem_colab_setup.ipynb`
- **Issues**: GitHub do projeto

---

**Ãšltima atualizaÃ§Ã£o**: 2024


