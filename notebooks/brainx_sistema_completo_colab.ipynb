{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ BrainX - Sistema Completo Adaptativo\n",
        "\n",
        "## ‚ö†Ô∏è IMPORTANTE: Este notebook foi otimizado para Google Colab com GPU\n",
        "\n",
        "**Para melhor performance:**\n",
        "1. Fa√ßa upload deste notebook no Google Colab: https://colab.research.google.com\n",
        "2. Habilite GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
        "3. Execute todas as c√©lulas na ordem\n",
        "\n",
        "**Funciona localmente tamb√©m**, mas ser√° mais lento sem GPU.\n",
        "\n",
        "---\n",
        "\n",
        "Sistema completo com todas as melhorias para superar todos os modelos:\n",
        "- ‚úÖ Prompts adaptativos por TRI\n",
        "- ‚úÖ Few-shots customizados por tema\n",
        "- ‚úÖ Detec√ß√£o de figuras simples\n",
        "- ‚úÖ Self-Consistency (m√∫ltiplas passagens)\n",
        "- ‚úÖ Prompt ultra-simples para quest√µes f√°ceis\n",
        "- ‚úÖ Prompt especializado para Natureza\n",
        "\n",
        "**Meta**: 94%+ acur√°cia (superar GPT-4o com 93.85%)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Instala√ß√£o e Configura√ß√£o\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "üîç VERIFICANDO AMBIENTE E GPU\n",
            "============================================================\n",
            "‚ö†Ô∏è  Executando LOCALMENTE (n√£o no Google Colab)\n",
            "   üí° Para melhor performance, use Google Colab com GPU\n",
            "   üìå Link: https://colab.research.google.com\n",
            "\n",
            "‚ö†Ô∏è  GPU n√£o dispon√≠vel (usando CPU)\n",
            "   üí° Para GPU, execute no Google Colab\n",
            "\n",
            "üí° Nota sobre Performance:\n",
            "   ‚ö†Ô∏è  Executando localmente - ser√° mais lento\n",
            "   üí° Recomendado: Use Google Colab com GPU para processar mais r√°pido\n",
            "   - Chamadas API s√£o via rede (n√£o usam GPU diretamente)\n",
            "   - Mas GPU permite otimiza√ß√µes e processamento paralelo\n"
          ]
        }
      ],
      "source": [
        "# Instalar depend√™ncias\n",
        "try:\n",
        "    get_ipython().run_line_magic('pip', 'install -q openai python-dotenv tqdm')\n",
        "except:\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', '-q', 'openai', 'python-dotenv', 'tqdm'])\n",
        "\n",
        "# Verificar GPU e ambiente\n",
        "print(\"üîç VERIFICANDO AMBIENTE E GPU\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verificar se est√° no Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    print(\"‚úÖ Google Colab detectado\")\n",
        "    IN_COLAB = True\n",
        "    print(\"üí° Para habilitar GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è  Executando LOCALMENTE (n√£o no Google Colab)\")\n",
        "    print(\"   üí° Para melhor performance, use Google Colab com GPU\")\n",
        "    print(\"   üìå Link: https://colab.research.google.com\")\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Verificar GPU\n",
        "USANDO_GPU = False\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        device_name = torch.cuda.get_device_name(0)\n",
        "        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        print(f\"\\n‚úÖ GPU dispon√≠vel: {device_name}\")\n",
        "        print(f\"   Mem√≥ria GPU: {memory_gb:.1f} GB\")\n",
        "        print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "        USANDO_GPU = True\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  GPU n√£o dispon√≠vel (usando CPU)\")\n",
        "        if IN_COLAB:\n",
        "            print(\"   üí° Dica: V√° em Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
        "        else:\n",
        "            print(\"   üí° Para GPU, execute no Google Colab\")\n",
        "except ImportError:\n",
        "    print(\"\\n‚ö†Ô∏è  PyTorch n√£o instalado\")\n",
        "    if IN_COLAB:\n",
        "        try:\n",
        "            get_ipython().run_line_magic('pip', 'install -q torch')\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            import torch\n",
        "            if torch.cuda.is_available():\n",
        "                print(f\"‚úÖ GPU dispon√≠vel: {torch.cuda.get_device_name(0)}\")\n",
        "                USANDO_GPU = True\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è  GPU n√£o dispon√≠vel\")\n",
        "        except:\n",
        "            pass\n",
        "    else:\n",
        "        print(\"   (PyTorch opcional para verifica√ß√£o local)\")\n",
        "\n",
        "# Verificar vari√°veis de ambiente\n",
        "import os\n",
        "if IN_COLAB:\n",
        "    print(f\"\\nüìä Informa√ß√µes do Colab:\")\n",
        "    print(f\"   COLAB_GPU: {os.environ.get('COLAB_GPU', 'n√£o definida')}\")\n",
        "\n",
        "print(f\"\\nüí° Nota sobre Performance:\")\n",
        "if IN_COLAB and USANDO_GPU:\n",
        "    print(f\"   ‚úÖ Ambiente otimizado: Colab + GPU\")\n",
        "elif IN_COLAB:\n",
        "    print(f\"   ‚ö†Ô∏è  Colab sem GPU - habilite GPU para melhor performance\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  Executando localmente - ser√° mais lento\")\n",
        "    print(f\"   üí° Recomendado: Use Google Colab com GPU para processar mais r√°pido\")\n",
        "print(f\"   - Chamadas API s√£o via rede (n√£o usam GPU diretamente)\")\n",
        "print(f\"   - Mas GPU permite otimiza√ß√µes e processamento paralelo\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Diret√≥rio inicial: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "üîß Detectado caminho duplicado! Corrigindo...\n",
            "   Caminho duplicado: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "   Caminho correto: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "‚úÖ Corrigido! Agora em: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "‚úÖ J√° estamos no diret√≥rio raiz do reposit√≥rio: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "üìÅ Diret√≥rio final: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "‚úÖ Diret√≥rio correto! scripts/analise_enem encontrado\n"
          ]
        }
      ],
      "source": [
        "# Clonar reposit√≥rio (com detec√ß√£o de caminho duplicado)\n",
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import shutil\n",
        "\n",
        "current_dir = Path.cwd()\n",
        "print(f\"üìÅ Diret√≥rio inicial: {current_dir}\")\n",
        "\n",
        "# DETECTAR E CORRIGIR CAMINHO DUPLICADO\n",
        "# Se o caminho cont√©m \"gpt-4-enem/gpt-4-enem\", estamos em um diret√≥rio duplicado\n",
        "path_str = str(current_dir)\n",
        "if path_str.count('gpt-4-enem') >= 2:\n",
        "    # Encontrar o primeiro \"gpt-4-enem\" v√°lido (que tem scripts/analise_enem)\n",
        "    parts = path_str.split('/')\n",
        "    for i in range(len(parts)):\n",
        "        if parts[i] == 'gpt-4-enem':\n",
        "            # Tentar caminho at√© este ponto\n",
        "            test_path = Path('/'.join(parts[:i+1]))\n",
        "            if (test_path / 'scripts' / 'analise_enem').exists():\n",
        "                print(f\"üîß Detectado caminho duplicado! Corrigindo...\")\n",
        "                print(f\"   Caminho duplicado: {current_dir}\")\n",
        "                print(f\"   Caminho correto: {test_path}\")\n",
        "                os.chdir(test_path)\n",
        "                current_dir = Path.cwd()\n",
        "                print(f\"‚úÖ Corrigido! Agora em: {current_dir}\")\n",
        "                break\n",
        "\n",
        "# Estrat√©gia: encontrar o diret√≥rio raiz do reposit√≥rio\n",
        "repo_root = None\n",
        "\n",
        "# Verificar se j√° estamos no diret√≥rio raiz do reposit√≥rio\n",
        "if (current_dir / 'scripts' / 'analise_enem').exists():\n",
        "    repo_root = current_dir\n",
        "    print(f\"‚úÖ J√° estamos no diret√≥rio raiz do reposit√≥rio: {repo_root}\")\n",
        "elif (current_dir.parent / 'scripts' / 'analise_enem').exists():\n",
        "    repo_root = current_dir.parent\n",
        "    print(f\"‚úÖ Reposit√≥rio encontrado no diret√≥rio pai: {repo_root}\")\n",
        "elif (current_dir.parent.parent / 'scripts' / 'analise_enem').exists():\n",
        "    repo_root = current_dir.parent.parent\n",
        "    print(f\"‚úÖ Reposit√≥rio encontrado 2 n√≠veis acima: {repo_root}\")\n",
        "\n",
        "# Se ainda n√£o encontrou, verificar se precisa clonar\n",
        "if repo_root is None:\n",
        "    # Verificar se o diret√≥rio atual √© \"gpt-4-enem\" ou est√° dentro dele\n",
        "    if current_dir.name == 'gpt-4-enem' and (current_dir / 'scripts' / 'analise_enem').exists():\n",
        "        repo_root = current_dir\n",
        "        print(f\"‚úÖ J√° estamos dentro do reposit√≥rio: {repo_root}\")\n",
        "    elif (current_dir / 'gpt-4-enem' / 'scripts' / 'analise_enem').exists():\n",
        "        repo_root = current_dir / 'gpt-4-enem'\n",
        "        print(f\"‚úÖ Reposit√≥rio encontrado em subdiret√≥rio: {repo_root}\")\n",
        "    else:\n",
        "        # Determinar onde clonar baseado no diret√≥rio atual\n",
        "        # Se estamos em notebooks/, ir para a raiz do Colab (geralmente /content)\n",
        "        if 'notebooks' in str(current_dir) or current_dir.name == 'notebooks':\n",
        "            # Ir para a raiz do Colab (geralmente /content)\n",
        "            colab_root = Path('/content') if Path('/content').exists() else current_dir\n",
        "            while colab_root.parent != colab_root:  # Enquanto n√£o for a raiz\n",
        "                if (colab_root / 'scripts' / 'analise_enem').exists():\n",
        "                    repo_root = colab_root\n",
        "                    break\n",
        "                if colab_root.parent == colab_root:\n",
        "                    break\n",
        "                colab_root = colab_root.parent\n",
        "            \n",
        "            if repo_root is None:\n",
        "                clone_target = colab_root / 'gpt-4-enem'\n",
        "                if (clone_target / 'scripts' / 'analise_enem').exists():\n",
        "                    repo_root = clone_target\n",
        "                    print(f\"‚úÖ Reposit√≥rio j√° existe: {repo_root}\")\n",
        "                elif not clone_target.exists():\n",
        "                    print(f\"üì• Clonando reposit√≥rio em: {clone_target.parent}\")\n",
        "                    subprocess.run(['git', 'clone', 'https://github.com/xtribr/enemnlp.git', str(clone_target)], \n",
        "                                 cwd=str(clone_target.parent), check=True)\n",
        "                    repo_root = clone_target\n",
        "                    print(f\"‚úÖ Reposit√≥rio clonado em: {repo_root}\")\n",
        "                else:\n",
        "                    repo_root = clone_target\n",
        "        else:\n",
        "            # Clonar no diret√≥rio atual\n",
        "            clone_target = current_dir / 'gpt-4-enem'\n",
        "            if not clone_target.exists():\n",
        "                print(f\"üì• Clonando reposit√≥rio...\")\n",
        "                subprocess.run(['git', 'clone', 'https://github.com/xtribr/enemnlp.git', 'gpt-4-enem'], \n",
        "                             cwd=str(current_dir), check=True)\n",
        "                repo_root = clone_target\n",
        "                print(f\"‚úÖ Reposit√≥rio clonado em: {repo_root}\")\n",
        "            elif (clone_target / 'scripts' / 'analise_enem').exists():\n",
        "                repo_root = clone_target\n",
        "                print(f\"‚úÖ Reposit√≥rio j√° existe: {repo_root}\")\n",
        "            else:\n",
        "                repo_root = clone_target\n",
        "\n",
        "# Mudar para o diret√≥rio raiz do reposit√≥rio\n",
        "if repo_root and repo_root.exists():\n",
        "    os.chdir(repo_root)\n",
        "    final_dir = Path.cwd()\n",
        "    print(f\"üìÅ Diret√≥rio final: {final_dir}\")\n",
        "    \n",
        "    # Verificar se est√° correto\n",
        "    if (final_dir / 'scripts' / 'analise_enem').exists():\n",
        "        print(\"‚úÖ Diret√≥rio correto! scripts/analise_enem encontrado\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Aten√ß√£o: scripts/analise_enem n√£o encontrado em {final_dir}\")\n",
        "        print(\"   A c√©lula seguinte tentar√° encontrar automaticamente\")\n",
        "else:\n",
        "    print(\"‚ùå N√£o foi poss√≠vel encontrar ou criar o reposit√≥rio\")\n",
        "    print(f\"   Diret√≥rio atual permanece: {Path.cwd()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ .env carregado\n",
            "‚úÖ Chave j√° configurada: ...697ebc2587\n"
          ]
        }
      ],
      "source": [
        "# Configurar API Key da Maritaca\n",
        "from getpass import getpass\n",
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Tentar carregar do .env se existir\n",
        "env_file = Path('.env')\n",
        "if env_file.exists():\n",
        "    load_dotenv(env_file)\n",
        "    print(\"‚úÖ .env carregado\")\n",
        "\n",
        "# Se n√£o estiver configurada, pedir ao usu√°rio\n",
        "if not os.getenv('CURSORMINIMAC') and not os.getenv('MARITALK_API_SECRET_KEY'):\n",
        "    print(\"üîë Configure sua chave API da Maritaca:\")\n",
        "    api_key = getpass(\"Cole sua chave (ser√° ocultada): \")\n",
        "    os.environ['CURSORMINIMAC'] = api_key\n",
        "    print(\"‚úÖ Chave configurada!\")\n",
        "else:\n",
        "    api_key = os.getenv('CURSORMINIMAC') or os.getenv('MARITALK_API_SECRET_KEY')\n",
        "    print(f\"‚úÖ Chave j√° configurada: ...{api_key[-10:] if api_key else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Importar Sistema BrainX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Diret√≥rio atual: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "üìÅ Diret√≥rio atual: /Users/bunker/gpt-4-enem/gpt-4-enem\n",
            "‚úÖ Usando scripts em: /Users/bunker/gpt-4-enem/gpt-4-enem/scripts/analise_enem\n",
            "\n",
            "üîç Verificando arquivos essenciais:\n",
            "   ‚úÖ 70_prompts_adaptativos_por_tri.py\n",
            "   ‚úÖ 75_deteccao_figuras_simples.py\n",
            "   ‚úÖ 79_prompt_ultra_simples_facil.py\n",
            "‚úÖ Prompts adaptativos carregados\n",
            "‚úÖ Few-shots customizados carregados\n",
            "‚úÖ Detec√ß√£o de figuras carregada\n",
            "‚úÖ Prompt ultra-simples carregado\n",
            "‚úÖ Few-shots Natureza carregados\n",
            "‚úÖ Prompt Natureza carregado\n",
            "\n",
            "‚úÖ Todos os m√≥dulos do BrainX carregados!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import json\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "import importlib.util\n",
        "import os\n",
        "\n",
        "# Verificar diret√≥rio atual e corrigir se necess√°rio\n",
        "current_dir = Path.cwd()\n",
        "print(f\"üìÅ Diret√≥rio atual: {current_dir}\")\n",
        "\n",
        "# Verificar diret√≥rio atual\n",
        "current_dir = Path.cwd()\n",
        "print(f\"üìÅ Diret√≥rio atual: {current_dir}\")\n",
        "\n",
        "# Verificar se scripts/analise_enem existe no diret√≥rio atual\n",
        "scripts_dir = current_dir / 'scripts' / 'analise_enem'\n",
        "\n",
        "if not scripts_dir.exists():\n",
        "    # Se n√£o existe, procurar em locais alternativos\n",
        "    print(\"üîç Procurando scripts/analise_enem em locais alternativos...\")\n",
        "    \n",
        "    possible_paths = [\n",
        "        current_dir / 'scripts' / 'analise_enem',\n",
        "        current_dir / 'gpt-4-enem' / 'scripts' / 'analise_enem',\n",
        "        current_dir.parent / 'scripts' / 'analise_enem',\n",
        "        current_dir.parent.parent / 'scripts' / 'analise_enem',\n",
        "        Path('/content') / 'gpt-4-enem' / 'scripts' / 'analise_enem',  # Colab padr√£o\n",
        "        Path('/content') / 'enemnlp' / 'scripts' / 'analise_enem',  # Se clonou como enemnlp\n",
        "    ]\n",
        "    \n",
        "    found_path = None\n",
        "    for path in possible_paths:\n",
        "        if path.exists():\n",
        "            found_path = path\n",
        "            # Mudar para o diret√≥rio raiz (2 n√≠veis acima de scripts/analise_enem)\n",
        "            project_root = path.parent.parent\n",
        "            os.chdir(project_root)\n",
        "            scripts_dir = Path('scripts/analise_enem')\n",
        "            print(f\"‚úÖ Encontrado em: {found_path}\")\n",
        "            print(f\"üìÅ Mudando para diret√≥rio raiz: {Path.cwd()}\")\n",
        "            break\n",
        "    \n",
        "    if found_path is None:\n",
        "        print(f\"‚ùå Diret√≥rio scripts/analise_enem n√£o encontrado!\")\n",
        "        print(f\"   Diret√≥rio atual: {Path.cwd()}\")\n",
        "        print(f\"   Tentamos os seguintes caminhos:\")\n",
        "        for path in possible_paths:\n",
        "            exists = path.exists()\n",
        "            print(f\"     - {path} {'‚úÖ' if exists else '‚ùå'}\")\n",
        "        print(f\"\\n   Conte√∫do do diret√≥rio atual:\")\n",
        "        try:\n",
        "            items = list(Path('.').iterdir())\n",
        "            for item in items[:15]:  # Mostrar mais itens\n",
        "                print(f\"     - {item.name} {'(dir)' if item.is_dir() else ''}\")\n",
        "            if len(items) > 15:\n",
        "                print(f\"     ... e mais {len(items) - 15} itens\")\n",
        "        except Exception as e:\n",
        "            print(f\"     Erro ao listar: {e}\")\n",
        "        print(f\"\\nüí° Solu√ß√£o: Certifique-se de que o reposit√≥rio foi clonado completamente\")\n",
        "        raise FileNotFoundError(f\"Diret√≥rio scripts/analise_enem n√£o encontrado. Verifique se o reposit√≥rio foi clonado corretamente.\")\n",
        "\n",
        "# Verificar novamente ap√≥s poss√≠vel mudan√ßa de diret√≥rio\n",
        "if not scripts_dir.exists():\n",
        "    scripts_dir = Path('scripts/analise_enem')\n",
        "    \n",
        "if not scripts_dir.exists():\n",
        "    raise FileNotFoundError(f\"scripts/analise_enem n√£o existe em {Path.cwd()}\")\n",
        "\n",
        "# Verificar se arquivos essenciais existem\n",
        "arquivos_essenciais = [\n",
        "    '70_prompts_adaptativos_por_tri.py',\n",
        "    '75_deteccao_figuras_simples.py',\n",
        "    '79_prompt_ultra_simples_facil.py'\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Usando scripts em: {scripts_dir.absolute()}\")\n",
        "print(f\"\\nüîç Verificando arquivos essenciais:\")\n",
        "arquivos_faltando = []\n",
        "for arquivo in arquivos_essenciais:\n",
        "    arquivo_path = scripts_dir / arquivo\n",
        "    if arquivo_path.exists():\n",
        "        print(f\"   ‚úÖ {arquivo}\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {arquivo} - N√ÉO ENCONTRADO!\")\n",
        "        arquivos_faltando.append(arquivo)\n",
        "\n",
        "if arquivos_faltando:\n",
        "    print(f\"\\n‚ö†Ô∏è  Arquivos faltando: {', '.join(arquivos_faltando)}\")\n",
        "    print(f\"   Isso pode indicar que o reposit√≥rio n√£o foi clonado completamente\")\n",
        "    print(f\"   Tente clonar novamente ou verifique se os arquivos existem no GitHub\")\n",
        "\n",
        "# Adicionar scripts ao path\n",
        "sys.path.insert(0, str(scripts_dir.absolute()))\n",
        "sys.path.insert(0, str(Path('.').absolute()))\n",
        "\n",
        "# Importar m√≥dulos do BrainX\n",
        "# Prompts adaptativos\n",
        "prompts_path = scripts_dir / '70_prompts_adaptativos_por_tri.py'\n",
        "if not prompts_path.exists():\n",
        "    print(f\"‚ùå ERRO: Arquivo n√£o encontrado: {prompts_path.absolute()}\")\n",
        "    print(f\"\\nüîß Tentando solu√ß√µes alternativas...\")\n",
        "    \n",
        "    # Tentar baixar do GitHub se n√£o existir\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/70_prompts_adaptativos_por_tri.py\"\n",
        "        print(f\"   üì• Baixando do GitHub: {github_url}\")\n",
        "        urllib.request.urlretrieve(github_url, str(prompts_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Erro ao baixar: {str(e)[:100]}\")\n",
        "        raise FileNotFoundError(f\"Arquivo n√£o encontrado e n√£o foi poss√≠vel baixar: {prompts_path.absolute()}\")\n",
        "\n",
        "spec = importlib.util.spec_from_file_location('prompts_adaptativos', str(prompts_path.absolute()))\n",
        "prompts_module = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(prompts_module)\n",
        "print(\"‚úÖ Prompts adaptativos carregados\")\n",
        "\n",
        "# Few-shots\n",
        "fewshots_path = scripts_dir / '73_fewshots_customizados_por_tema.py'\n",
        "if not fewshots_path.exists():\n",
        "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado, tentando baixar do GitHub...\")\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/73_fewshots_customizados_por_tema.py\"\n",
        "        urllib.request.urlretrieve(github_url, str(fewshots_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado!\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  N√£o foi poss√≠vel baixar: {str(e)[:100]}\")\n",
        "        fewshots_module = None\n",
        "        print(\"‚ö†Ô∏è  Few-shots customizados n√£o encontrado (opcional)\")\n",
        "else:\n",
        "    spec2 = importlib.util.spec_from_file_location('fewshots_customizados', str(fewshots_path.absolute()))\n",
        "    fewshots_module = importlib.util.module_from_spec(spec2)\n",
        "    spec2.loader.exec_module(fewshots_module)\n",
        "    print(\"‚úÖ Few-shots customizados carregados\")\n",
        "\n",
        "# Detec√ß√£o de figuras\n",
        "figuras_path = scripts_dir / '75_deteccao_figuras_simples.py'\n",
        "if not figuras_path.exists():\n",
        "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado, tentando baixar do GitHub...\")\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/75_deteccao_figuras_simples.py\"\n",
        "        urllib.request.urlretrieve(github_url, str(figuras_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado!\")\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {figuras_path.absolute()}\")\n",
        "spec3 = importlib.util.spec_from_file_location('deteccao_figuras', str(figuras_path.absolute()))\n",
        "figuras_module = importlib.util.module_from_spec(spec3)\n",
        "spec3.loader.exec_module(figuras_module)\n",
        "print(\"‚úÖ Detec√ß√£o de figuras carregada\")\n",
        "\n",
        "# Prompt simples\n",
        "simples_path = scripts_dir / '79_prompt_ultra_simples_facil.py'\n",
        "if not simples_path.exists():\n",
        "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado, tentando baixar do GitHub...\")\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/79_prompt_ultra_simples_facil.py\"\n",
        "        urllib.request.urlretrieve(github_url, str(simples_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado!\")\n",
        "    except Exception as e:\n",
        "        raise FileNotFoundError(f\"Arquivo n√£o encontrado: {simples_path.absolute()}\")\n",
        "spec4 = importlib.util.spec_from_file_location('prompt_simples', str(simples_path.absolute()))\n",
        "simples_module = importlib.util.module_from_spec(spec4)\n",
        "spec4.loader.exec_module(simples_module)\n",
        "print(\"‚úÖ Prompt ultra-simples carregado\")\n",
        "\n",
        "# Few-shots Natureza\n",
        "natureza_path = scripts_dir / '81_fewshots_natureza_expandido.py'\n",
        "if not natureza_path.exists():\n",
        "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado, tentando baixar do GitHub...\")\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/81_fewshots_natureza_expandido.py\"\n",
        "        urllib.request.urlretrieve(github_url, str(natureza_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado!\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  N√£o foi poss√≠vel baixar: {str(e)[:100]}\")\n",
        "        natureza_module = None\n",
        "        print(\"‚ö†Ô∏è  Few-shots Natureza n√£o encontrado (opcional)\")\n",
        "else:\n",
        "    spec5 = importlib.util.spec_from_file_location('fewshots_natureza', str(natureza_path.absolute()))\n",
        "    natureza_module = importlib.util.module_from_spec(spec5)\n",
        "    spec5.loader.exec_module(natureza_module)\n",
        "    print(\"‚úÖ Few-shots Natureza carregados\")\n",
        "\n",
        "# Prompt Natureza\n",
        "prompt_nat_path = scripts_dir / '82_prompt_especializado_natureza.py'\n",
        "if not prompt_nat_path.exists():\n",
        "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado, tentando baixar do GitHub...\")\n",
        "    try:\n",
        "        import urllib.request\n",
        "        github_url = \"https://raw.githubusercontent.com/xtribr/enemnlp/main/scripts/analise_enem/82_prompt_especializado_natureza.py\"\n",
        "        urllib.request.urlretrieve(github_url, str(prompt_nat_path))\n",
        "        print(f\"   ‚úÖ Arquivo baixado!\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è  N√£o foi poss√≠vel baixar: {str(e)[:100]}\")\n",
        "        prompt_nat_module = None\n",
        "        print(\"‚ö†Ô∏è  Prompt Natureza n√£o encontrado (opcional)\")\n",
        "else:\n",
        "    spec6 = importlib.util.spec_from_file_location('prompt_natureza', str(prompt_nat_path.absolute()))\n",
        "    prompt_nat_module = importlib.util.module_from_spec(spec6)\n",
        "    spec6.loader.exec_module(prompt_nat_module)\n",
        "    print(\"‚úÖ Prompt Natureza carregado\")\n",
        "\n",
        "print(\"\\n‚úÖ Todos os m√≥dulos do BrainX carregados!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fun√ß√µes auxiliares carregadas!\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "def configurar_api_colab():\n",
        "    \"\"\"Configura API para Colab\"\"\"\n",
        "    api_key = os.getenv('CURSORMINIMAC') or os.getenv('MARITALK_API_SECRET_KEY')\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Chave API n√£o configurada!\")\n",
        "    \n",
        "    return openai.OpenAI(\n",
        "        api_key=api_key,\n",
        "        base_url=\"https://chat.maritaca.ai/api\"\n",
        "    )\n",
        "\n",
        "def extrair_resposta(texto: str) -> Optional[str]:\n",
        "    \"\"\"Extrai resposta do modelo - vers√£o melhorada\"\"\"\n",
        "    if not texto:\n",
        "        return None\n",
        "    \n",
        "    import re\n",
        "    texto_upper = texto.upper().strip()\n",
        "    \n",
        "    # Padr√µes expl√≠citos (prioridade alta)\n",
        "    padroes_explicitos = [\n",
        "        r'RESPOSTA:\\s*([A-E])',\n",
        "        r'ALTERNATIVA\\s*([A-E])',\n",
        "        r'GABARITO:\\s*([A-E])',\n",
        "        r'A\\s*RESPOSTA\\s*√â\\s*([A-E])',\n",
        "        r'RESPOSTA\\s*CORRETA:\\s*([A-E])',\n",
        "        r'LETRA\\s*([A-E])',\n",
        "    ]\n",
        "    \n",
        "    for padrao in padroes_explicitos:\n",
        "        match = re.search(padrao, texto_upper)\n",
        "        if match:\n",
        "            letra = match.group(1)\n",
        "            if letra in ['A', 'B', 'C', 'D', 'E']:\n",
        "                return letra\n",
        "    \n",
        "    # Procurar por padr√µes como \"A)\", \"B)\", etc no final do texto\n",
        "    padroes_finais = re.findall(r'\\b([A-E])\\s*[\\)\\.:]?\\s*$', texto_upper[-200:])\n",
        "    if padroes_finais:\n",
        "        letra = padroes_finais[-1]\n",
        "        if letra in ['A', 'B', 'C', 'D', 'E']:\n",
        "            return letra\n",
        "    \n",
        "    # √öltimo recurso: procurar qualquer letra A-E isolada no final\n",
        "    # (mas com cuidado para n√£o pegar letras no meio do texto)\n",
        "    palavras_finais = texto_upper.split()[-10:]  # √öltimas 10 palavras\n",
        "    for palavra in reversed(palavras_finais):\n",
        "        palavra_limpa = re.sub(r'[^A-E]', '', palavra)\n",
        "        if palavra_limpa in ['A', 'B', 'C', 'D', 'E']:\n",
        "            return palavra_limpa\n",
        "    \n",
        "    return None\n",
        "\n",
        "def carregar_questoes_colab(anos=None, apenas_2024=False, incluir_treino=True):\n",
        "    \"\"\"\n",
        "    Carrega quest√µes de TODAS as fontes: ENEM, ITA, IME, FUVEST, UNICAMP\n",
        "    \n",
        "    Args:\n",
        "        anos: Lista de anos ENEM para carregar (ex: [2022, 2023, 2024]). Se None, carrega todos.\n",
        "        apenas_2024: Se True, carrega apenas ENEM 2024 (180 quest√µes). Se False, carrega todos os anos ENEM.\n",
        "        incluir_treino: Se True, carrega tamb√©m ITA, IME, FUVEST, UNICAMP de data/treino/\n",
        "    \n",
        "    Returns:\n",
        "        Dict com quest√µes organizadas por √°rea\n",
        "    \"\"\"\n",
        "    processed_dir = Path('data/processed')\n",
        "    treino_dir = Path('data/treino')\n",
        "    \n",
        "    questoes_por_area = {\n",
        "        'languages': [],\n",
        "        'human-sciences': [],\n",
        "        'natural-sciences': [],\n",
        "        'mathematics': []\n",
        "    }\n",
        "    \n",
        "    total_carregado = 0\n",
        "    \n",
        "    # ===== CARREGAR ENEM =====\n",
        "    if processed_dir.exists():\n",
        "        if apenas_2024:\n",
        "            arquivos_enem = [processed_dir / 'enem_2024_completo.jsonl']\n",
        "            print(\"üìÅ Carregando apenas ENEM 2024 (180 quest√µes)\")\n",
        "        else:\n",
        "            if anos:\n",
        "                arquivos_enem = [processed_dir / f'enem_{ano}_completo.jsonl' for ano in anos]\n",
        "            else:\n",
        "                arquivos_enem = sorted(processed_dir.glob('enem_*_completo.jsonl'))\n",
        "            print(f\"üìÅ Carregando ENEM: {len(arquivos_enem)} arquivo(s)\")\n",
        "        \n",
        "        for arquivo in arquivos_enem:\n",
        "            if not arquivo.exists():\n",
        "                continue\n",
        "            \n",
        "            ano = arquivo.stem.replace('enem_', '').replace('_completo', '')\n",
        "            \n",
        "            try:\n",
        "                with open(arquivo, 'r', encoding='utf-8') as f:\n",
        "                    count_arquivo = 0\n",
        "                    for line in f:\n",
        "                        if line.strip():\n",
        "                            questao = json.loads(line)\n",
        "                            num_str = questao.get('id', '').replace('questao_', '') or questao.get('number', '')\n",
        "                            \n",
        "                            try:\n",
        "                                num = int(num_str)\n",
        "                                # Classificar por n√∫mero (ENEM sempre tem 45 por √°rea)\n",
        "                                if 1 <= num <= 45:\n",
        "                                    area = 'languages'\n",
        "                                elif 46 <= num <= 90:\n",
        "                                    area = 'human-sciences'\n",
        "                                elif 91 <= num <= 135:\n",
        "                                    area = 'natural-sciences'\n",
        "                                elif 136 <= num <= 180:\n",
        "                                    area = 'mathematics'\n",
        "                                else:\n",
        "                                    continue\n",
        "                                \n",
        "                                # Adicionar informa√ß√£o\n",
        "                                questao['number'] = num\n",
        "                                questao['area'] = area\n",
        "                                questao['ano'] = ano\n",
        "                                questao['exame'] = 'ENEM'\n",
        "                                \n",
        "                                questoes_por_area[area].append(questao)\n",
        "                                count_arquivo += 1\n",
        "                                total_carregado += 1\n",
        "                            except (ValueError, TypeError):\n",
        "                                continue\n",
        "                    \n",
        "                    if count_arquivo > 0:\n",
        "                        print(f\"   ‚úÖ ENEM {ano}: {count_arquivo} quest√µes\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Erro ao carregar {arquivo.name}: {str(e)[:50]}\")\n",
        "                continue\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Diret√≥rio ENEM n√£o encontrado: {processed_dir}\")\n",
        "    \n",
        "    # ===== CARREGAR ITA, IME, FUVEST, UNICAMP =====\n",
        "    if incluir_treino and treino_dir.exists():\n",
        "        print(f\"\\nüìÅ Carregando quest√µes de treino (ITA, IME, FUVEST, UNICAMP)...\")\n",
        "        \n",
        "        arquivos_treino = [\n",
        "            ('FUVEST', treino_dir / 'treino_fuvest.jsonl'),\n",
        "            ('ITA', treino_dir / 'treino_ita.jsonl'),\n",
        "            ('IME', treino_dir / 'treino_ime.jsonl'),\n",
        "            ('UNICAMP', treino_dir / 'treino_unicamp.jsonl'),\n",
        "        ]\n",
        "        \n",
        "        for exame_nome, arquivo in arquivos_treino:\n",
        "            if not arquivo.exists():\n",
        "                continue\n",
        "            \n",
        "            try:\n",
        "                with open(arquivo, 'r', encoding='utf-8') as f:\n",
        "                    count_arquivo = 0\n",
        "                    for line in f:\n",
        "                        if line.strip():\n",
        "                            questao = json.loads(line)\n",
        "                            \n",
        "                            # Quest√µes de treino j√° t√™m 'area' definida\n",
        "                            area = questao.get('area', '').lower()\n",
        "                            \n",
        "                            # Mapear √°reas\n",
        "                            if area in ['languages', 'human-sciences', 'natural-sciences', 'mathematics']:\n",
        "                                # Adicionar informa√ß√£o do exame\n",
        "                                questao['exame'] = exame_nome\n",
        "                                questao['exam_type'] = questao.get('exam_type', exame_nome.lower())\n",
        "                                \n",
        "                                questoes_por_area[area].append(questao)\n",
        "                                count_arquivo += 1\n",
        "                                total_carregado += 1\n",
        "                    \n",
        "                    if count_arquivo > 0:\n",
        "                        print(f\"   ‚úÖ {exame_nome}: {count_arquivo} quest√µes\")\n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ö†Ô∏è  Erro ao carregar {arquivo.name}: {str(e)[:50]}\")\n",
        "                continue\n",
        "    elif incluir_treino:\n",
        "        print(f\"‚ö†Ô∏è  Diret√≥rio de treino n√£o encontrado: {treino_dir}\")\n",
        "    \n",
        "    # ===== ESTAT√çSTICAS FINAIS =====\n",
        "    print(f\"\\nüìä Total carregado: {total_carregado} quest√µes\")\n",
        "    print(f\"\\nüìä Por √°rea:\")\n",
        "    for area, questoes in questoes_por_area.items():\n",
        "        print(f\"   {area}: {len(questoes)} quest√µes\")\n",
        "    \n",
        "    # Estat√≠sticas por exame\n",
        "    exames_count = {}\n",
        "    for area_questoes in questoes_por_area.values():\n",
        "        for q in area_questoes:\n",
        "            exame = q.get('exame', 'Desconhecido')\n",
        "            exames_count[exame] = exames_count.get(exame, 0) + 1\n",
        "    \n",
        "    if exames_count:\n",
        "        print(f\"\\nüìä Por exame:\")\n",
        "        for exame, count in sorted(exames_count.items()):\n",
        "            print(f\"   {exame}: {count} quest√µes\")\n",
        "    \n",
        "    return questoes_por_area\n",
        "\n",
        "print(\"‚úÖ Fun√ß√µes auxiliares carregadas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Preparando diret√≥rios de dados...\n",
            "   ‚úÖ data/processed\n",
            "   ‚úÖ data/treino\n",
            "   ‚úÖ results\n",
            "\n",
            "üìä Status dos dados:\n",
            "   ENEM: 21 arquivo(s) encontrado(s)\n",
            "   Treino: 5 arquivo(s) encontrado(s)\n",
            "\n",
            "‚úÖ Dados encontrados! Pronto para carregar quest√µes.\n"
          ]
        }
      ],
      "source": [
        "# üîß PREPARAR DIRET√ìRIOS DE DADOS\n",
        "# Criar diret√≥rios se n√£o existirem\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "data_dirs = [\n",
        "    Path('data/processed'),\n",
        "    Path('data/treino'),\n",
        "    Path('results')\n",
        "]\n",
        "\n",
        "print(\"üìÅ Preparando diret√≥rios de dados...\")\n",
        "for dir_path in data_dirs:\n",
        "    dir_path.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"   ‚úÖ {dir_path}\")\n",
        "\n",
        "# Verificar se h√° dados\n",
        "processed_dir = Path('data/processed')\n",
        "treino_dir = Path('data/treino')\n",
        "\n",
        "enem_files = list(processed_dir.glob('enem_*.jsonl')) if processed_dir.exists() else []\n",
        "treino_files = list(treino_dir.glob('treino_*.jsonl')) if treino_dir.exists() else []\n",
        "\n",
        "print(f\"\\nüìä Status dos dados:\")\n",
        "print(f\"   ENEM: {len(enem_files)} arquivo(s) encontrado(s)\")\n",
        "print(f\"   Treino: {len(treino_files)} arquivo(s) encontrado(s)\")\n",
        "\n",
        "if len(enem_files) == 0 and len(treino_files) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  NENHUM DADO ENCONTRADO!\")\n",
        "    print(\"\\nüí° OP√á√ïES PARA CARREGAR DADOS:\")\n",
        "    print(\"\\n   1. FAZER UPLOAD MANUAL (Recomendado):\")\n",
        "    print(\"      - Clique no √≠cone de pasta üìÅ no Colab\")\n",
        "    print(\"      - Fa√ßa upload dos arquivos:\")\n",
        "    print(\"        * data/processed/enem_2024_completo.jsonl\")\n",
        "    print(\"        * data/treino/treino_*.jsonl (opcional)\")\n",
        "    print(\"\\n   2. BAIXAR DADOS DO GITHUB (se dispon√≠veis):\")\n",
        "    print(\"      - Execute a c√©lula abaixo para tentar baixar\")\n",
        "    print(\"\\n   3. USAR DADOS DE EXEMPLO:\")\n",
        "    print(\"      - O sistema pode funcionar com dados m√≠nimos\")\n",
        "    print(\"      - Mas acur√°cia ser√° limitada\")\n",
        "    \n",
        "    print(\"\\nüí° SOLU√á√ÉO: Fazer upload do DATASET COMPLETO\")\n",
        "    print(\"\\n   Op√ß√£o 1: Upload via c√≥digo (pr√≥xima c√©lula) - RECOMENDADO\")\n",
        "    print(\"      - Execute a c√©lula 10\")\n",
        "    print(\"      - Selecione TODOS os arquivos de uma vez:\")\n",
        "    print(\"        * ENEM 2009-2025 (17 arquivos)\")\n",
        "    print(\"        * Treino: FUVEST, ITA, IME, UNICAMP (4 arquivos)\")\n",
        "    print(\"\\n   Op√ß√£o 2: Upload manual via interface do Colab\")\n",
        "    print(\"      - Clique no √≠cone üìÅ (pasta) na barra lateral\")\n",
        "    print(\"      - Navegue at√© data/processed/ e fa√ßa upload de todos os ENEM\")\n",
        "    print(\"      - Navegue at√© data/treino/ e fa√ßa upload de todos os treinos\")\n",
        "    print(\"\\n   ‚ö†Ô∏è  IMPORTANTE: Os dados n√£o est√£o no GitHub (est√£o no .gitignore)\")\n",
        "    print(\"      Voc√™ precisa fazer upload do dataset completo dos seus arquivos locais\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ Dados encontrados! Pronto para carregar quest√µes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è  N√£o est√° no Google Colab!\n",
            "   Esta c√©lula s√≥ funciona no Colab.\n",
            "   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\n",
            "üì§ UPLOAD DE DATASET COMPLETO\n",
            "======================================================================\n",
            "\n",
            "üí° INSTRU√á√ïES:\n",
            "   1. Execute esta c√©lula\n",
            "   2. Clique em 'Escolher arquivos' e selecione TODOS os arquivos de uma vez:\n",
            "      - ENEM: enem_2009_completo.jsonl at√© enem_2025_completo.jsonl (17 arquivos)\n",
            "      - Treino: treino_fuvest.jsonl, treino_ita.jsonl, treino_ime.jsonl, treino_unicamp.jsonl\n",
            "   3. Os arquivos ser√£o organizados automaticamente nas pastas corretas\n",
            "\n",
            "üìÅ DATASET COMPLETO:\n",
            "   üìö ENEM (2009-2025):\n",
            "      - enem_2009_completo.jsonl\n",
            "      - enem_2010_completo.jsonl\n",
            "      - ... (at√© 2025)\n",
            "      - enem_2025_completo.jsonl\n",
            "   üìö TREINO:\n",
            "      - treino_fuvest.jsonl\n",
            "      - treino_ita.jsonl\n",
            "      - treino_ime.jsonl\n",
            "      - treino_unicamp.jsonl\n",
            "\n",
            "üí° DICA: Voc√™ pode selecionar m√∫ltiplos arquivos de uma vez!\n",
            "   - No Windows/Linux: Ctrl+Clique para selecionar m√∫ltiplos\n",
            "   - No Mac: Cmd+Clique para selecionar m√∫ltiplos\n",
            "\n",
            "‚ö†Ô∏è  Alternativa: Use a interface do Colab (√≠cone üìÅ na barra lateral)\n",
            "   - Fa√ßa upload diretamente nas pastas data/processed/ e data/treino/\n",
            "\n",
            "======================================================================\n",
            "\n",
            "‚ùå Esta funcionalidade requer Google Colab.\n",
            "   Use a interface do Colab (√≠cone üìÅ na barra lateral) para fazer upload.\n",
            "\n",
            "‚ö†Ô∏è  Nenhum arquivo selecionado.\n",
            "   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\n"
          ]
        }
      ],
      "source": [
        "# üì§ UPLOAD DE DATASET COMPLETO\n",
        "# Fa√ßa upload de TODOS os arquivos de uma vez!\n",
        "# Voc√™ pode selecionar m√∫ltiplos arquivos simultaneamente\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Detectar se est√° no Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  N√£o est√° no Google Colab!\")\n",
        "    print(\"   Esta c√©lula s√≥ funciona no Colab.\")\n",
        "    print(\"   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\")\n",
        "    files = None\n",
        "\n",
        "print(\"üì§ UPLOAD DE DATASET COMPLETO\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nüí° INSTRU√á√ïES:\")\n",
        "print(\"   1. Execute esta c√©lula\")\n",
        "print(\"   2. Clique em 'Escolher arquivos' e selecione TODOS os arquivos de uma vez:\")\n",
        "print(\"      - ENEM: enem_2009_completo.jsonl at√© enem_2025_completo.jsonl (17 arquivos)\")\n",
        "print(\"      - Treino: treino_fuvest.jsonl, treino_ita.jsonl, treino_ime.jsonl, treino_unicamp.jsonl\")\n",
        "print(\"   3. Os arquivos ser√£o organizados automaticamente nas pastas corretas\")\n",
        "print(\"\\nüìÅ DATASET COMPLETO:\")\n",
        "print(\"   üìö ENEM (2009-2025):\")\n",
        "print(\"      - enem_2009_completo.jsonl\")\n",
        "print(\"      - enem_2010_completo.jsonl\")\n",
        "print(\"      - ... (at√© 2025)\")\n",
        "print(\"      - enem_2025_completo.jsonl\")\n",
        "print(\"   üìö TREINO:\")\n",
        "print(\"      - treino_fuvest.jsonl\")\n",
        "print(\"      - treino_ita.jsonl\")\n",
        "print(\"      - treino_ime.jsonl\")\n",
        "print(\"      - treino_unicamp.jsonl\")\n",
        "print(\"\\nüí° DICA: Voc√™ pode selecionar m√∫ltiplos arquivos de uma vez!\")\n",
        "print(\"   - No Windows/Linux: Ctrl+Clique para selecionar m√∫ltiplos\")\n",
        "print(\"   - No Mac: Cmd+Clique para selecionar m√∫ltiplos\")\n",
        "print(\"\\n‚ö†Ô∏è  Alternativa: Use a interface do Colab (√≠cone üìÅ na barra lateral)\")\n",
        "print(\"   - Fa√ßa upload diretamente nas pastas data/processed/ e data/treino/\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "# Criar diret√≥rios se n√£o existirem\n",
        "Path('data/processed').mkdir(parents=True, exist_ok=True)\n",
        "Path('data/treino').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not IN_COLAB:\n",
        "    print(\"\\n‚ùå Esta funcionalidade requer Google Colab.\")\n",
        "    print(\"   Use a interface do Colab (√≠cone üìÅ na barra lateral) para fazer upload.\")\n",
        "else:\n",
        "    print(\"\\nüîΩ Selecione os arquivos para upload...\")\n",
        "    print(\"   (Pressione Ctrl+C se preferir fazer upload manual)\")\n",
        "\n",
        "try:\n",
        "    if not IN_COLAB:\n",
        "        uploaded = {}\n",
        "    else:\n",
        "        uploaded = files.upload()\n",
        "    \n",
        "    if uploaded:\n",
        "        print(f\"\\n‚úÖ {len(uploaded)} arquivo(s) recebido(s)!\")\n",
        "        \n",
        "        for filename, content in uploaded.items():\n",
        "            # Determinar destino baseado no nome\n",
        "            if 'enem_' in filename and filename.endswith('.jsonl'):\n",
        "                dest = Path('data/processed') / filename\n",
        "            elif 'treino_' in filename and filename.endswith('.jsonl'):\n",
        "                dest = Path('data/treino') / filename\n",
        "            else:\n",
        "                # Tentar adivinhar\n",
        "                if 'processed' in filename or 'enem' in filename.lower():\n",
        "                    dest = Path('data/processed') / filename\n",
        "                else:\n",
        "                    dest = Path('data/treino') / filename\n",
        "            \n",
        "            # Salvar arquivo\n",
        "            dest.parent.mkdir(parents=True, exist_ok=True)\n",
        "            with open(dest, 'wb') as f:\n",
        "                f.write(content)\n",
        "            \n",
        "            size_kb = len(content) / 1024\n",
        "            print(f\"   ‚úÖ {filename} ‚Üí {dest} ({size_kb:.1f} KB)\")\n",
        "        \n",
        "        print(\"\\nüéâ Upload conclu√≠do! Execute a c√©lula anterior novamente para verificar.\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è  Nenhum arquivo selecionado.\")\n",
        "        print(\"   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\")\n",
        "        \n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\n‚ö†Ô∏è  Upload cancelado.\")\n",
        "    print(\"   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Erro durante upload: {str(e)}\")\n",
        "    print(\"   Use a interface do Colab (√≠cone üìÅ) para fazer upload manualmente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fun√ß√£o atualizada detectada\n",
            "üìÅ Carregando ENEM: 17 arquivo(s)\n",
            "   ‚úÖ ENEM 2024: 180 quest√µes\n",
            "\n",
            "üìÅ Carregando quest√µes de treino (ITA, IME, FUVEST, UNICAMP)...\n",
            "   ‚úÖ FUVEST: 1282 quest√µes\n",
            "   ‚úÖ ITA: 714 quest√µes\n",
            "   ‚úÖ IME: 147 quest√µes\n",
            "   ‚úÖ UNICAMP: 708 quest√µes\n",
            "\n",
            "üìä Total carregado: 3031 quest√µes\n",
            "\n",
            "üìä Por √°rea:\n",
            "   languages: 562 quest√µes\n",
            "   human-sciences: 721 quest√µes\n",
            "   natural-sciences: 1224 quest√µes\n",
            "   mathematics: 524 quest√µes\n",
            "\n",
            "üìä Por exame:\n",
            "   ENEM: 180 quest√µes\n",
            "   FUVEST: 1282 quest√µes\n",
            "   IME: 147 quest√µes\n",
            "   ITA: 714 quest√µes\n",
            "   UNICAMP: 708 quest√µes\n",
            "\n",
            "‚úÖ Total: 3031 quest√µes carregadas\n",
            "   Linguagens: 562 quest√µes\n",
            "   Humanas: 721 quest√µes\n",
            "   Natureza: 1224 quest√µes\n",
            "   Matem√°tica: 524 quest√µes\n"
          ]
        }
      ],
      "source": [
        "# Configurar\n",
        "client = configurar_api_colab()\n",
        "\n",
        "# CARREGAR QUEST√ïES\n",
        "# Verificar se a fun√ß√£o tem os par√¢metros novos\n",
        "import inspect\n",
        "try:\n",
        "    sig = inspect.signature(carregar_questoes_colab)\n",
        "    params = list(sig.parameters.keys())\n",
        "    tem_parametro_novo = 'apenas_2024' in params\n",
        "    \n",
        "    if tem_parametro_novo:\n",
        "        print(\"‚úÖ Fun√ß√£o atualizada detectada\")\n",
        "        # Op√ß√£o 1: Apenas ENEM 2024 (180 quest√µes) - mais r√°pido para testes\n",
        "        # questoes_por_area = carregar_questoes_colab(apenas_2024=True)\n",
        "        \n",
        "        # Op√ß√£o 2: Todos os anos dispon√≠veis (dataset completo) - RECOMENDADO\n",
        "        questoes_por_area = carregar_questoes_colab(apenas_2024=False)\n",
        "        \n",
        "        # Op√ß√£o 3: Anos espec√≠ficos (ex: √∫ltimos 3 anos)\n",
        "        # questoes_por_area = carregar_questoes_colab(anos=[2022, 2023, 2024])\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Fun√ß√£o antiga detectada - usando vers√£o compat√≠vel\")\n",
        "        print(\"   (Execute a c√©lula 8 novamente para usar vers√£o completa)\")\n",
        "        # Vers√£o compat√≠vel: chamar sem par√¢metros (carrega apenas 2024)\n",
        "        questoes_por_area = carregar_questoes_colab()\n",
        "        \n",
        "except NameError:\n",
        "    print(\"‚ùå ERRO: Fun√ß√£o carregar_questoes_colab n√£o encontrada!\")\n",
        "    print(\"   Execute a c√©lula 8 primeiro!\")\n",
        "    raise\n",
        "except TypeError as e:\n",
        "    # Se der erro de par√¢metro, tentar sem par√¢metros\n",
        "    print(\"‚ö†Ô∏è  Tentando vers√£o compat√≠vel...\")\n",
        "    questoes_por_area = carregar_questoes_colab()\n",
        "\n",
        "area_names = {\n",
        "    'languages': 'Linguagens',\n",
        "    'human-sciences': 'Humanas',\n",
        "    'natural-sciences': 'Natureza',\n",
        "    'mathematics': 'Matem√°tica'\n",
        "}\n",
        "\n",
        "total = sum(len(q) for q in questoes_por_area.values())\n",
        "print(f\"\\n‚úÖ Total: {total} quest√µes carregadas\")\n",
        "for area, name in area_names.items():\n",
        "    count = len(questoes_por_area.get(area, []))\n",
        "    print(f\"   {name}: {count} quest√µes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Configura√ß√£o - Aproveitando GPU do Colab:\n",
            "   Quest√µes por √°rea: 45\n",
            "   Passagens (self-consistency): 5\n",
            "   Total de quest√µes: 180\n",
            "   Total de chamadas API: 900\n",
            "   Tempo estimado: ~7.5 minutos\n"
          ]
        }
      ],
      "source": [
        "# Configura√ß√£o do teste - APROVEITANDO PODER DE PROCESSAMENTO!\n",
        "# Op√ß√µes:\n",
        "# - TESTE R√ÅPIDO: QUESTOES_POR_AREA = 10, N_PASSAGENS = 3\n",
        "# - TESTE M√âDIO: QUESTOES_POR_AREA = 45, N_PASSAGENS = 5 (recomendado)\n",
        "# - TESTE COMPLETO: QUESTOES_POR_AREA = None (todas), N_PASSAGENS = 7 (m√°xima qualidade)\n",
        "\n",
        "QUESTOES_POR_AREA = 45  # 45 = todas as quest√µes de uma √°rea do ENEM (ou None para todas)\n",
        "N_PASSAGENS = 5  # Self-consistency (3=r√°pido, 5=balanceado, 7=m√°xima qualidade)\n",
        "\n",
        "print(f\"üìä Configura√ß√£o - Aproveitando GPU do Colab:\")\n",
        "print(f\"   Quest√µes por √°rea: {QUESTOES_POR_AREA if QUESTOES_POR_AREA else 'TODAS'}\")\n",
        "print(f\"   Passagens (self-consistency): {N_PASSAGENS}\")\n",
        "if QUESTOES_POR_AREA:\n",
        "    total_questoes = QUESTOES_POR_AREA * 4\n",
        "    total_api_calls = total_questoes * N_PASSAGENS\n",
        "    tempo_estimado = (total_api_calls * 0.5) / 60  # ~0.5s por chamada\n",
        "    print(f\"   Total de quest√µes: {total_questoes}\")\n",
        "    print(f\"   Total de chamadas API: {total_api_calls}\")\n",
        "    print(f\"   Tempo estimado: ~{tempo_estimado:.1f} minutos\")\n",
        "else:\n",
        "    print(f\"   Total de quest√µes: TODAS dispon√≠veis\")\n",
        "    print(f\"   ‚ö†Ô∏è  Isso pode levar muito tempo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fun√ß√µes de avalia√ß√£o carregadas!\n"
          ]
        }
      ],
      "source": [
        "# Fun√ß√£o completa de avalia√ß√£o\n",
        "def construir_prompt_final_colab(questao, prompts_module, fewshots_module, figuras_module, \n",
        "                                simples_module, natureza_module, prompt_nat_module):\n",
        "    \"\"\"Constr√≥i prompt final com todas as melhorias\"\"\"\n",
        "    num = questao.get('number', 0)\n",
        "    area = questao.get('area', '')\n",
        "    \n",
        "    # Obter TRI (s√≥ funciona para Matem√°tica 136-180)\n",
        "    tri_info = prompts_module.obter_info_tri(num)\n",
        "    tri_value = tri_info.get('TRI', 0)\n",
        "    nivel = prompts_module.classificar_por_tri(tri_value) if tri_value > 0 else 'medio'\n",
        "    tema = tri_info.get('Tema', 'N/A')\n",
        "    \n",
        "    # Prompt adaptativo baseado em TRI (se dispon√≠vel) ou √°rea\n",
        "    if tri_value > 0:\n",
        "        # Temos TRI - usar prompt adaptativo\n",
        "        prompt_base = prompts_module.selecionar_prompt_por_tri(tri_value)\n",
        "    else:\n",
        "        # Sem TRI - criar prompt espec√≠fico por √°rea\n",
        "        if area == 'languages':\n",
        "            prompt_base = \"\"\"Voc√™ √© um especialista em quest√µes de Linguagens do ENEM.\n",
        "\n",
        "Esta quest√£o envolve interpreta√ß√£o de texto, gram√°tica, literatura ou artes.\n",
        "\n",
        "üìã METODOLOGIA PARA LINGUAGENS:\n",
        "\n",
        "1. LEITURA ATENTA\n",
        "   - Leia o texto/contexto com cuidado\n",
        "   - Identifique o g√™nero textual\n",
        "   - Observe elementos de coes√£o e coer√™ncia\n",
        "\n",
        "2. AN√ÅLISE DA PERGUNTA\n",
        "   - O que exatamente est√° sendo perguntado?\n",
        "   - √â sobre interpreta√ß√£o, gram√°tica, literatura ou artes?\n",
        "   - Identifique palavras-chave na pergunta\n",
        "\n",
        "3. AN√ÅLISE DAS ALTERNATIVAS\n",
        "   - Leia todas as alternativas antes de escolher\n",
        "   - Elimine alternativas claramente incorretas\n",
        "   - Compare com o texto/contexto fornecido\n",
        "\n",
        "4. VALIDA√á√ÉO\n",
        "   - Sua resposta est√° fundamentada no texto?\n",
        "   - Faz sentido no contexto?\n",
        "   - Responde exatamente o que foi perguntado?\n",
        "\n",
        "Agora, resolva a quest√£o abaixo:\n",
        "\n",
        "\"\"\"\n",
        "        elif area == 'human-sciences':\n",
        "            prompt_base = \"\"\"Voc√™ √© um especialista em quest√µes de Ci√™ncias Humanas do ENEM.\n",
        "\n",
        "Esta quest√£o envolve Hist√≥ria, Geografia, Filosofia ou Sociologia.\n",
        "\n",
        "üìã METODOLOGIA PARA CI√äNCIAS HUMANAS:\n",
        "\n",
        "1. CONTEXTUALIZA√á√ÉO\n",
        "   - Identifique o per√≠odo hist√≥rico ou contexto geogr√°fico\n",
        "   - Relacione com conceitos de Hist√≥ria, Geografia, Filosofia ou Sociologia\n",
        "   - Observe dados, mapas ou gr√°ficos fornecidos\n",
        "\n",
        "2. AN√ÅLISE DA PERGUNTA\n",
        "   - O que est√° sendo perguntado?\n",
        "   - Qual √°rea do conhecimento (Hist√≥ria, Geografia, Filosofia, Sociologia)?\n",
        "   - Identifique conceitos-chave\n",
        "\n",
        "3. RELA√á√ÉO COM O CONTEXTO\n",
        "   - Relacione a pergunta com o contexto fornecido\n",
        "   - Use conhecimentos hist√≥ricos/geogr√°ficos relevantes\n",
        "   - Considere m√∫ltiplas perspectivas quando aplic√°vel\n",
        "\n",
        "4. AN√ÅLISE DAS ALTERNATIVAS\n",
        "   - Elimine alternativas anacr√¥nicas ou geograficamente incorretas\n",
        "   - Compare com o contexto fornecido\n",
        "   - Verifique se a resposta est√° fundamentada\n",
        "\n",
        "Agora, resolva a quest√£o abaixo:\n",
        "\n",
        "\"\"\"\n",
        "        elif area == 'natural-sciences':\n",
        "            prompt_base = \"\"\"Voc√™ √© um especialista em quest√µes de Ci√™ncias da Natureza do ENEM.\n",
        "\n",
        "Esta quest√£o envolve F√≠sica, Qu√≠mica ou Biologia.\n",
        "\n",
        "üìã METODOLOGIA PARA CI√äNCIAS DA NATUREZA:\n",
        "\n",
        "1. IDENTIFICA√á√ÉO DO PROBLEMA\n",
        "   - Leia o contexto e a pergunta\n",
        "   - Identifique a √°rea (F√≠sica, Qu√≠mica ou Biologia)\n",
        "   - Anote os dados fornecidos\n",
        "\n",
        "2. CONCEITOS CIENT√çFICOS\n",
        "   - Identifique os conceitos cient√≠ficos envolvidos\n",
        "   - Relacione com f√≥rmulas ou princ√≠pios quando aplic√°vel\n",
        "   - Considere unidades de medida\n",
        "\n",
        "3. RESOLU√á√ÉO\n",
        "   - Resolva passo a passo\n",
        "   - Mostre c√°lculos quando necess√°rio\n",
        "   - Verifique cada etapa\n",
        "\n",
        "4. VALIDA√á√ÉO\n",
        "   - Verifique se a resposta faz sentido cientificamente\n",
        "   - Confirme unidades e ordens de grandeza\n",
        "   - Compare com as alternativas\n",
        "\n",
        "Agora, resolva a quest√£o abaixo:\n",
        "\n",
        "\"\"\"\n",
        "        else:\n",
        "            # Matem√°tica sem TRI ou √°rea desconhecida\n",
        "            prompt_base = \"\"\"Voc√™ √© um especialista em quest√µes do ENEM. Resolva passo-a-passo.\n",
        "\n",
        "üìã METODOLOGIA:\n",
        "\n",
        "1. Leia o contexto e a pergunta com aten√ß√£o\n",
        "2. Identifique o que est√° sendo pedido\n",
        "3. Resolva passo a passo\n",
        "4. Verifique se a resposta faz sentido\n",
        "5. Escolha a alternativa correta\n",
        "\n",
        "Agora, resolva a quest√£o abaixo:\n",
        "\n",
        "\"\"\"\n",
        "    \n",
        "    # Prompt ultra-simples se f√°cil\n",
        "    if tri_value > 0 and tri_value < 650:\n",
        "        prompt_base = simples_module.aplicar_prompt_ultra_simples(\n",
        "            prompt_base, questao, tri_value, figuras_module.obter_info_figura\n",
        "        )\n",
        "    \n",
        "    # Few-shots e prompts espec√≠ficos\n",
        "    if area == 'natural-sciences' and prompt_nat_module:\n",
        "        prompt_base = prompt_nat_module.criar_prompt_natureza(prompt_base)\n",
        "        if nivel == 'medio' and natureza_module:\n",
        "            fewshots = natureza_module.obter_fewshots_natureza(5)\n",
        "            for fs in fewshots:\n",
        "                prompt_base += f\"\\n\\nExemplo:\\n{fs['question']}\\n{fs['response']}\\n\"\n",
        "    elif area == 'mathematics' and nivel == 'medio' and fewshots_module:\n",
        "        prompt_base = fewshots_module.criar_prompt_com_fewshots(prompt_base, tema, 3)\n",
        "    \n",
        "    # Detec√ß√£o de figuras\n",
        "    prompt_final = figuras_module.criar_prompt_com_deteccao_figura(prompt_base, questao)\n",
        "    \n",
        "    return prompt_final, {'tri': tri_value, 'nivel': nivel, 'tema': tema, 'area': area}\n",
        "\n",
        "def formatar_questao_colab(questao):\n",
        "    \"\"\"Formata quest√£o\"\"\"\n",
        "    texto = \"\"\n",
        "    if questao.get('context'):\n",
        "        texto += f\"CONTEXTO:\\n{questao['context']}\\n\\n\"\n",
        "    if questao.get('description'):\n",
        "        desc = questao['description']\n",
        "        if isinstance(desc, list) and desc:\n",
        "            texto += f\"DESCRI√á√ÉO DAS IMAGENS:\\n{desc[0]}\\n\\n\"\n",
        "        elif desc:\n",
        "            texto += f\"DESCRI√á√ÉO DAS IMAGENS:\\n{desc}\\n\\n\"\n",
        "    texto += f\"PERGUNTA:\\n{questao.get('question', '')}\\n\\n\"\n",
        "    texto += \"ALTERNATIVAS:\\n\"\n",
        "    for i, alt in enumerate(questao.get('alternatives', []), 1):\n",
        "        letra = chr(64 + i)\n",
        "        texto += f\"{letra}) {alt}\\n\"\n",
        "    return texto\n",
        "\n",
        "def resolver_com_self_consistency_colab(client, questao, n_passagens, prompts_module, \n",
        "                                         fewshots_module, figuras_module, simples_module,\n",
        "                                         natureza_module, prompt_nat_module, usar_paralelo=False):\n",
        "    \"\"\"\n",
        "    Resolve com self-consistency\n",
        "    \n",
        "    Args:\n",
        "        usar_paralelo: Se True, tenta processar passagens em paralelo (requer GPU/threading)\n",
        "    \"\"\"\n",
        "    respostas = []\n",
        "    \n",
        "    prompt_final, info = construir_prompt_final_colab(\n",
        "        questao, prompts_module, fewshots_module, figuras_module,\n",
        "        simples_module, natureza_module, prompt_nat_module\n",
        "    )\n",
        "    questao_formatada = formatar_questao_colab(questao)\n",
        "    prompt_completo = prompt_final + questao_formatada\n",
        "    \n",
        "    # Otimiza√ß√£o: reduzir delay se GPU dispon√≠vel\n",
        "    delay = 0.1 if usar_paralelo else 0.2\n",
        "    \n",
        "    for i in range(n_passagens):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"sabia-3\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em quest√µes do ENEM.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt_completo}\n",
        "                ],\n",
        "                temperature=0.1,\n",
        "                max_tokens=2000\n",
        "            )\n",
        "            \n",
        "            resposta_texto = response.choices[0].message.content\n",
        "            resposta_extraida = extrair_resposta(resposta_texto)\n",
        "            \n",
        "            if resposta_extraida:\n",
        "                respostas.append(resposta_extraida)\n",
        "            \n",
        "            time.sleep(delay)  # Delay reduzido se GPU dispon√≠vel\n",
        "        except Exception as e:\n",
        "            print(f\"      ‚ö†Ô∏è  Erro passagem {i+1}: {str(e)[:50]}\")\n",
        "            continue\n",
        "    \n",
        "    if not respostas:\n",
        "        return None, 0.0, info\n",
        "    \n",
        "    # Vota√ß√£o majorit√°ria\n",
        "    contador = Counter(respostas)\n",
        "    resposta_mais_frequente = contador.most_common(1)[0]\n",
        "    resposta_final = resposta_mais_frequente[0]\n",
        "    frequencia = resposta_mais_frequente[1]\n",
        "    confianca = frequencia / len(respostas)\n",
        "    \n",
        "    return resposta_final, confianca, info\n",
        "\n",
        "print(\"‚úÖ Fun√ß√µes de avalia√ß√£o carregadas!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üöÄ AVALIA√á√ÉO COMPLETA - BRAINX\n",
            "======================================================================\n",
            "\n",
            "‚ö†Ô∏è  GPU n√£o detectada - processamento padr√£o\n",
            "\n",
            "üìö Linguagens (45 quest√µes)\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Linguagens:   0%|          | 0/45 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m total_geral += \u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m stats_por_area[area_name][\u001b[33m'\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m'\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m resposta_final, confianca, info = \u001b[43mresolver_com_self_consistency_colab\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_PASSAGENS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfewshots_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiguras_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimples_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnatureza_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_nat_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43musar_paralelo\u001b[49m\u001b[43m=\u001b[49m\u001b[43musar_gpu_otimizado\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Normalizar label (garantir mai√∫scula)\u001b[39;00m\n\u001b[32m     57\u001b[39m correct_answer_raw = q.get(\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m q.get(\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m q.get(\u001b[33m'\u001b[39m\u001b[33mgabarito\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 188\u001b[39m, in \u001b[36mresolver_com_self_consistency_colab\u001b[39m\u001b[34m(client, questao, n_passagens, prompts_module, fewshots_module, figuras_module, simples_module, natureza_module, prompt_nat_module, usar_paralelo)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_passagens):\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m         response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msabia-3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVoc√™ √© um especialista em quest√µes do ENEM.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_completo\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m         resposta_texto = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m    199\u001b[39m         resposta_extraida = extrair_resposta(resposta_texto)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:1189\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1142\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1143\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1186\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1187\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1188\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/openai/_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    980\u001b[39m response = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    988\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/gpt-4-enem/gpt-4-enem/.conda/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# EXECUTAR AVALIA√á√ÉO COMPLETA\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ AVALIA√á√ÉO COMPLETA - BRAINX\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "# Verificar se GPU est√° dispon√≠vel para otimiza√ß√£o\n",
        "try:\n",
        "    import torch\n",
        "    usar_gpu_otimizado = torch.cuda.is_available()\n",
        "    if usar_gpu_otimizado:\n",
        "        print(\"‚úÖ GPU detectada - usando otimiza√ß√µes\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  GPU n√£o detectada - processamento padr√£o\")\n",
        "except:\n",
        "    usar_gpu_otimizado = False\n",
        "\n",
        "stats_por_area = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
        "resultados = []\n",
        "total_geral = 0\n",
        "correct_geral = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for area_key, area_name in area_names.items():\n",
        "    questoes = questoes_por_area.get(area_key, [])\n",
        "    \n",
        "    # Limitar se QUESTOES_POR_AREA estiver definido\n",
        "    if QUESTOES_POR_AREA:\n",
        "        questoes = questoes[:QUESTOES_POR_AREA]\n",
        "    \n",
        "    # Se n√£o h√° limite, usar todas (mas avisar)\n",
        "    if not QUESTOES_POR_AREA and len(questoes) > 100:\n",
        "        print(f\"‚ö†Ô∏è  {area_name}: {len(questoes)} quest√µes - isso pode levar muito tempo!\")\n",
        "    \n",
        "    if not questoes:\n",
        "        print(f\"‚ö†Ô∏è  Nenhuma quest√£o para {area_name}\")\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\nüìö {area_name} ({len(questoes)} quest√µes)\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    # Otimiza√ß√£o: reduzir delay entre quest√µes se GPU dispon√≠vel\n",
        "    delay_entre_questoes = 0.1 if usar_gpu_otimizado else 0.3\n",
        "    \n",
        "    for q in tqdm(questoes, desc=f\"{area_name}\"):\n",
        "        q_num = q.get('number', 0)\n",
        "        total_geral += 1\n",
        "        stats_por_area[area_name]['total'] += 1\n",
        "        \n",
        "        resposta_final, confianca, info = resolver_com_self_consistency_colab(\n",
        "            client, q, N_PASSAGENS, prompts_module, fewshots_module,\n",
        "            figuras_module, simples_module, natureza_module, prompt_nat_module,\n",
        "            usar_paralelo=usar_gpu_otimizado\n",
        "        )\n",
        "        \n",
        "        # Normalizar label (garantir mai√∫scula)\n",
        "        correct_answer_raw = q.get('label', '') or q.get('answer', '') or q.get('gabarito', '')\n",
        "        correct_answer = str(correct_answer_raw).upper().strip()\n",
        "        \n",
        "        # Validar que √© uma alternativa v√°lida\n",
        "        if correct_answer not in ['A', 'B', 'C', 'D', 'E']:\n",
        "            print(f\"  Q{q_num}: ‚ö†Ô∏è  Gabarito inv√°lido: '{correct_answer_raw}'\")\n",
        "            correct_answer = ''\n",
        "        \n",
        "        # Comparar (normalizar resposta tamb√©m)\n",
        "        resposta_normalizada = str(resposta_final).upper().strip() if resposta_final else ''\n",
        "        is_correct = (resposta_normalizada == correct_answer) if (resposta_normalizada and correct_answer) else False\n",
        "        \n",
        "        if is_correct:\n",
        "            correct_geral += 1\n",
        "            stats_por_area[area_name]['correct'] += 1\n",
        "            print(f\"  Q{q_num}: ‚úÖ ({resposta_final}, conf: {confianca:.0%})\")\n",
        "        else:\n",
        "            print(f\"  Q{q_num}: ‚ùå ({resposta_final} vs {correct_answer}, conf: {confianca:.0%})\")\n",
        "        \n",
        "        resultados.append({\n",
        "            'area': area_name,\n",
        "            'numero': q_num,\n",
        "            'resposta': resposta_final,\n",
        "            'gabarito': correct_answer,\n",
        "            'correto': is_correct,\n",
        "            'confianca': confianca\n",
        "        })\n",
        "        \n",
        "        time.sleep(delay_entre_questoes)  # Delay otimizado\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "accuracy_geral = correct_geral / total_geral if total_geral > 0 else 0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä RESULTADOS FINAIS\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "print(f\"üéØ Acur√°cia Geral: {accuracy_geral:.2%} ({correct_geral}/{total_geral})\")\n",
        "print(f\"‚è±Ô∏è  Tempo: {elapsed_time:.1f}s ({elapsed_time/total_geral:.1f}s por quest√£o)\")\n",
        "print()\n",
        "\n",
        "print(\"üìä Por √Årea:\")\n",
        "print(\"-\" * 50)\n",
        "for area_name in ['Linguagens', 'Humanas', 'Natureza', 'Matem√°tica']:\n",
        "    stats = stats_por_area[area_name]\n",
        "    if stats['total'] > 0:\n",
        "        acc = stats['correct'] / stats['total']\n",
        "        print(f\"{area_name:<15} {stats['correct']:>3}/{stats['total']:<3} = {acc:>5.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"üìà Compara√ß√£o:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"BrainX (Teste):     {accuracy_geral:.2%}\")\n",
        "print(f\"BrainX (Atual):     86.59%\")\n",
        "print(f\"GPT-4o (Paper):     93.85%\")\n",
        "print(f\"Gap para GPT-4o:    {93.85 - accuracy_geral*100:+.2f} pontos\")\n",
        "\n",
        "if accuracy_geral >= 0.94:\n",
        "    print(\"\\nüéâ PARAB√âNS! BrainX superou GPT-4o!\")\n",
        "elif accuracy_geral >= 0.90:\n",
        "    print(\"\\n‚úÖ Excelente! Muito pr√≥ximo do GPT-4o!\")\n",
        "elif accuracy_geral >= 0.87:\n",
        "    print(\"\\n‚úÖ Bom resultado! Melhorias funcionando!\")\n",
        "\n",
        "# Salvar resultados\n",
        "from datetime import datetime\n",
        "output_file = Path(f\"results/avaliacao_colab_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
        "output_file.parent.mkdir(exist_ok=True)\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump({\n",
        "        'total': total_geral,\n",
        "        'correct': correct_geral,\n",
        "        'accuracy': accuracy_geral,\n",
        "        'stats_por_area': dict(stats_por_area),\n",
        "        'resultados': resultados,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nüíæ Resultados salvos em: {output_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
