#!/usr/bin/env python3
"""
Teste r√°pido do prompt melhorado em amostra de quest√µes

Compara o desempenho do prompt melhorado com o anterior.
"""
import json
import sys
import os
from pathlib import Path
from typing import Dict, List
import time
import random

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

def configurar_api_maritaca():
    """Configura conex√£o com API Maritaca"""
    import openai
    
    api_key = (
        os.environ.get("CURSORMINIMAC") or
        os.environ.get("MARITALK_API_SECRET_KEY") or
        os.environ.get("MARITACA_API_KEY")
    )
    
    if not api_key:
        print("‚ùå Chave API n√£o configurada!")
        return None, None
    
    openai.api_base = "https://chat.maritaca.ai/api"
    openai_version = openai.__version__
    major_version = int(openai_version.split('.')[0])
    
    if major_version >= 1:
        client = openai.OpenAI(api_key=api_key, base_url="https://chat.maritaca.ai/api")
        return client, 'v1'
    else:
        openai.api_key = api_key
        return openai, 'v0'

def formatar_questao_para_maritaca(questao: Dict, usar_campos_semanticos: bool = True) -> str:
    """Formata quest√£o com prompt melhorado (baseado na an√°lise da Maritaca)"""
    contexto = questao.get('context', '').strip()
    pergunta = questao.get('question', '').strip()
    alternativas = questao.get('alternatives', [])
    area = questao.get('area', 'desconhecida')
    campos_semanticos = questao.get('campos_semanticos', [])
    
    area_nomes = {
        'languages': 'Linguagens, C√≥digos e suas Tecnologias',
        'human-sciences': 'Ci√™ncias Humanas e suas Tecnologias',
        'natural-sciences': 'Ci√™ncias da Natureza e suas Tecnologias',
        'mathematics': 'Matem√°tica e suas Tecnologias'
    }
    area_nome = area_nomes.get(area, area)
    
    instrucoes_especificas = {
        'mathematics': """
ATEN√á√ÉO CR√çTICA PARA MATEM√ÅTICA (√°rea com maior dificuldade):
- Quest√µes de matem√°tica frequentemente envolvem m√∫ltiplos passos de resolu√ß√£o
- QUEBRE O PROBLEMA EM ETAPAS CLARAS e resolva cada uma individualmente
- Identifique e aplique f√≥rmulas relevantes, mostrando cada substitui√ß√£o de vari√°veis
- Verifique todos os c√°lculos aritm√©ticos e alg√©bricos com cuidado
- Preste aten√ß√£o EXTREMA a detalhes num√©ricos e unidades de medida
- Use CHECAGEM DIMENSIONAL: elimine alternativas com unidades incorretas
- Use ESTIMATIVAS R√ÅPIDAS para eliminar op√ß√µes claramente desproporcionais
- Ap√≥s resolver, VERIFIQUE se a resposta se encaixa nos dados fornecidos
- Traduza corretamente problemas de palavras em equa√ß√µes matem√°ticas
- N√ÉO escolha uma alternativa sem verificar os c√°lculos passo a passo
""",
    }
    
    prompt = f"""Voc√™ √© um especialista em avalia√ß√µes educacionais do ENEM (Exame Nacional do Ensino M√©dio).

√ÅREA DE CONHECIMENTO: {area_nome}
"""
    
    if usar_campos_semanticos and campos_semanticos:
        prompt += f"CAMPOS SEM√ÇNTICOS IDENTIFICADOS: {', '.join(campos_semanticos)}\n"
        prompt += "Use esses campos para contextualizar melhor a quest√£o.\n"
    
    prompt += instrucoes_especificas.get(area, "")
    
    prompt += f"""
METODOLOGIA DE RESOLU√á√ÉO OBRIGAT√ìRIA (siga estes passos em ordem):

PASSO 1 - INTERPRETA√á√ÉO DO PROBLEMA:
- Leia o contexto completo com aten√ß√£o total
- Identifique EXATAMENTE o que a pergunta est√° pedindo
- Sublinhe ou liste mentalmente os dados fornecidos
- Identifique palavras-chave que indicam opera√ß√µes ou conceitos espec√≠ficos

PASSO 2 - ESCOLHA DA ABORDAGEM:
- Decida qual m√©todo, f√≥rmula ou conceito aplicar
- Para matem√°tica: identifique as f√≥rmulas relevantes
- Para ci√™ncias: identifique os princ√≠pios cient√≠ficos envolvidos
- Para linguagens/humanas: identifique o tema central e inten√ß√£o

PASSO 3 - RESOLU√á√ÉO PASSO A PASSO:
- Quebre o problema em etapas menores e resolva cada uma individualmente
- Para matem√°tica: mostre cada substitui√ß√£o de vari√°veis e c√°lculo
- Execute a resolu√ß√£o de forma sistem√°tica
- N√ÉO pule etapas

PASSO 4 - ELIMINA√á√ÉO DE ALTERNATIVAS:
Analise CADA alternativa individualmente e elimine as incorretas:
- Checagem Dimensional (matem√°tica/ci√™ncias): Verifique se as unidades est√£o corretas
- Estimativas: Use estimativas r√°pidas para eliminar op√ß√µes claramente desproporcionais
- Verifica√ß√£o Conceitual: A alternativa est√° correta do ponto de vista t√©cnico/conceitual?
- Verifica√ß√£o Contextual: A alternativa faz sentido no contexto apresentado?
- Resposta Direta: A alternativa responde diretamente √† pergunta feita?

PASSO 5 - VERIFICA√á√ÉO FINAL:
- Revise se a resposta faz sentido no contexto do problema
- Verifique se est√° em conformidade com as unidades de medida (se aplic√°vel)
- Confirme que a resposta responde corretamente √† pergunta feita
- N√ÉO escolha uma alternativa apenas porque parece plaus√≠vel

PASSO 6 - ESCOLHA FINAL:
- Compare as alternativas restantes cuidadosamente
- Escolha a alternativa que melhor responde √† pergunta
- Se n√£o tiver certeza, analise novamente - N√ÉO escolha B por padr√£o
- Evite qualquer vi√©s em dire√ß√£o a uma alternativa espec√≠fica

CONTEXTO:
{contexto}

PERGUNTA:
{pergunta}

ALTERNATIVAS:
"""
    
    for i, alt in enumerate(alternativas, 1):
        letra = chr(64 + i)
        prompt += f"{letra}. {alt}\n"
    
    prompt += """
RESPOSTA FINAL:
Ap√≥s seguir TODOS os 6 passos da metodologia acima, responda APENAS com a letra da alternativa correta (A, B, C, D ou E).

IMPORTANTE:
- N√ÉO inclua explica√ß√µes, apenas a letra
- N√ÉO escolha B por padr√£o em caso de incerteza
- Se n√£o tiver certeza ap√≥s seguir todos os passos, analise novamente
- A resposta deve ser baseada na resolu√ß√£o passo a passo, n√£o em intui√ß√£o"""
    
    return prompt

def avaliar_questao(client, questao: Dict, versao: str, usar_campos_semanticos: bool = True) -> Dict:
    """Avalia uma quest√£o usando API Maritaca"""
    prompt = formatar_questao_para_maritaca(questao, usar_campos_semanticos)
    resposta_correta = questao.get('label', '').upper().strip()
    
    try:
        if versao == 'v1':
            response = client.chat.completions.create(
                model="sabia-3",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=5,
                temperature=0.0
            )
            resposta_ia = response.choices[0].message.content.strip().upper()
        else:
            response = client.ChatCompletion.create(
                model="sabia-3",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=5,
                temperature=0.0
            )
            resposta_ia = response.choices[0].message.content.strip().upper()
        
        resposta_ia = resposta_ia[0] if resposta_ia and resposta_ia[0] in ['A', 'B', 'C', 'D', 'E'] else None
        acerto = resposta_ia == resposta_correta if resposta_ia else False
        
        return {
            'id': questao.get('id', ''),
            'resposta_correta': resposta_correta,
            'resposta_ia': resposta_ia,
            'acerto': acerto,
            'area': questao.get('area', 'desconhecida')
        }
    except Exception as e:
        return {
            'id': questao.get('id', ''),
            'resposta_correta': resposta_correta,
            'resposta_ia': None,
            'acerto': False,
            'erro': str(e)
        }

def carregar_amostra_questoes(num_questoes: int = 100, focar_matematica: bool = True):
    """Carrega amostra de quest√µes para teste"""
    project_root = Path(__file__).parent.parent.parent
    processed_dir = project_root / "data" / "processed"
    
    todas_questoes = []
    
    for jsonl_file in sorted(processed_dir.glob("enem_*_completo.jsonl")):
        with open(jsonl_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    questao = json.loads(line)
                    if questao.get('label', '').upper() not in ['ANULADO', '']:
                        todas_questoes.append(questao)
    
    if focar_matematica:
        questoes_matematica = [q for q in todas_questoes if q.get('area') == 'mathematics']
        questoes_outras = [q for q in todas_questoes if q.get('area') != 'mathematics']
        
        num_mat = min(int(num_questoes * 0.6), len(questoes_matematica))
        num_outras = num_questoes - num_mat
        
        amostra = random.sample(questoes_matematica, num_mat)
        amostra.extend(random.sample(questoes_outras, min(num_outras, len(questoes_outras))))
        random.shuffle(amostra)
    else:
        amostra = random.sample(todas_questoes, min(num_questoes, len(todas_questoes)))
    
    return amostra

def main():
    """Fun√ß√£o principal"""
    print("=" * 70)
    print("üß™ TESTE R√ÅPIDO - PROMPT MELHORADO")
    print("=" * 70)
    print()
    print("üìä Testando prompt melhorado baseado na an√°lise da Maritaca")
    print("   Foco: Matem√°tica (√°rea com maior dificuldade - 33.52%)")
    print()
    
    # Configurar API
    client, versao = configurar_api_maritaca()
    if not client:
        return
    
    # Carregar amostra
    print("üì• Carregando amostra de 100 quest√µes (60% matem√°tica)...")
    questoes = carregar_amostra_questoes(num_questoes=100, focar_matematica=True)
    print(f"‚úÖ {len(questoes)} quest√µes carregadas")
    print()
    
    # Avaliar
    print("üîÑ Avaliando com prompt melhorado...")
    print()
    
    resultados = []
    acertos = 0
    
    for i, questao in enumerate(questoes, 1):
        print(f"  [{i}/{len(questoes)}] {questao.get('id', '')[:30]}...", end=' ')
        
        resultado = avaliar_questao(client, questao, versao, usar_campos_semanticos=True)
        resultados.append(resultado)
        
        if resultado.get('acerto'):
            acertos += 1
            print("‚úÖ")
        else:
            print(f"‚ùå (IA: {resultado.get('resposta_ia', 'N/A')}, Correta: {resultado.get('resposta_correta', 'N/A')})")
        
        time.sleep(0.5)
    
    acuracia = (acertos / len(questoes) * 100) if questoes else 0
    
    # An√°lise
    print()
    print("=" * 70)
    print("üìä RESULTADOS DO TESTE")
    print("=" * 70)
    print(f"Total: {len(questoes)} quest√µes")
    print(f"Acertos: {acertos}")
    print(f"Erros: {len(questoes) - acertos}")
    print(f"Acur√°cia: {acuracia:.2f}%")
    print()
    
    # Por √°rea
    resultados_por_area = {}
    for res in resultados:
        area = res.get('area', 'desconhecida')
        if area not in resultados_por_area:
            resultados_por_area[area] = {'total': 0, 'acertos': 0}
        resultados_por_area[area]['total'] += 1
        if res.get('acerto'):
            resultados_por_area[area]['acertos'] += 1
    
    print("üìä Acur√°cia por √°rea:")
    for area, dados in sorted(resultados_por_area.items()):
        acuracia_area = (dados['acertos'] / dados['total'] * 100) if dados['total'] > 0 else 0
        print(f"   {area:20s}: {acuracia_area:5.2f}% ({dados['acertos']}/{dados['total']})")
    
    # Compara√ß√£o
    print()
    print("üìà Compara√ß√£o com resultado anterior:")
    print(f"   Acur√°cia anterior: 73.79%")
    print(f"   Acur√°cia atual:    {acuracia:.2f}%")
    diferenca = acuracia - 73.79
    if diferenca > 0:
        print(f"   ‚úÖ Melhoria: +{diferenca:.2f}%")
    else:
        print(f"   ‚ö†Ô∏è  Redu√ß√£o: {diferenca:.2f}%")
    
    if 'mathematics' in resultados_por_area:
        mat_atual = (resultados_por_area['mathematics']['acertos'] / 
                    resultados_por_area['mathematics']['total'] * 100)
        print()
        print("üìä Matem√°tica (√°rea cr√≠tica):")
        print(f"   Acur√°cia anterior: 33.52%")
        print(f"   Acur√°cia atual:    {mat_atual:.2f}%")
        diferenca_mat = mat_atual - 33.52
        if diferenca_mat > 0:
            print(f"   ‚úÖ Melhoria: +{diferenca_mat:.2f}%")
        else:
            print(f"   ‚ö†Ô∏è  Redu√ß√£o: {diferenca_mat:.2f}%")
    
    print()
    print("=" * 70)
    
    # Salvar
    project_root = Path(__file__).parent.parent.parent
    arquivo = project_root / "data" / "analises" / "teste_rapido_prompt_melhorado.json"
    with open(arquivo, 'w', encoding='utf-8') as f:
        json.dump({
            'resultados': resultados,
            'total': len(questoes),
            'acertos': acertos,
            'acuracia': acuracia,
            'por_area': resultados_por_area
        }, f, indent=2, ensure_ascii=False)
    
    print(f"üíæ Resultados salvos em: {arquivo}")

if __name__ == "__main__":
    main()
