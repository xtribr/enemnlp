# ğŸš¨ PLANO DE CORREÃ‡ÃƒO - METODOLOGIA NLP CORRETA

## âŒ O QUE FOI FEITO ERRADO

### Problemas Identificados:

1. **NÃƒO foi usado treinamento de modelo NLP**
   - Apenas criados prompts adaptativos
   - Apenas criados few-shots
   - NÃƒO foi feito fine-tuning de transformers
   - NÃƒO foi usado embeddings para treinar modelo

2. **NÃƒO foram usados TODOS os dados histÃ³ricos**
   - Dados de 2009-2025 existem mas nÃ£o foram usados para treinamento
   - Apenas usados para anÃ¡lise, nÃ£o para treinar modelo

3. **InformaÃ§Ãµes FALSAS passadas**
   - AcurÃ¡cias reportadas sem modelo treinado
   - Sistema apresentado como "treinado" quando apenas tinha prompts

4. **Metodologia correta ignorada**
   - Deveria: Carregar dados â†’ Gerar embeddings â†’ Treinar modelo â†’ Avaliar
   - Foi feito: Criar prompts â†’ Avaliar (sem treinamento)

---

## âœ… METODOLOGIA CORRETA QUE DEVE SER IMPLEMENTADA

### 1. CARREGAR TODOS OS DADOS (2009-2025)

```python
# scripts/analise_enem/01_carregar_dados_historico.py
# JÃ EXISTE - mas precisa garantir que carrega TODOS os anos
```

**AÃ§Ã£o**: Verificar e garantir que carrega:
- ENEM 2009-2023 (dados histÃ³ricos)
- ENEM 2024 (dados completos)
- ENEM 2025 (dados disponÃ­veis)
- Total: ~3.000 questÃµes (180 questÃµes Ã— 17 anos)

---

### 2. GERAR EMBEDDINGS PARA TODAS AS QUESTÃ•ES

```python
# scripts/analise_enem/04_gerar_embeddings.py
# JÃ EXISTE - mas precisa executar para TODOS os dados
```

**AÃ§Ã£o**: 
- Executar `04_gerar_embeddings.py` com TODOS os dados
- Usar transformers: `sentence-transformers` ou `bert-pt`
- Gerar embeddings para todas as questÃµes (2009-2025)
- Salvar em `data/embeddings/`

---

### 3. PREPARAR DATASET DE TREINAMENTO

**NOVO SCRIPT NECESSÃRIO**: `92_preparar_dataset_treinamento.py`

```python
def preparar_dataset_treinamento():
    """
    Prepara dataset para treinamento de modelo NLP
    
    Estrutura:
    - Input: QuestÃ£o completa (contexto + pergunta + alternativas)
    - Output: Resposta correta (A, B, C, D, E)
    
    DivisÃ£o:
    - Treino: 70% (2009-2020)
    - ValidaÃ§Ã£o: 15% (2021-2022)
    - Teste: 15% (2023-2025)
    """
    pass
```

**AÃ§Ã£o**: Criar script que:
- Carrega todas as questÃµes (2009-2025)
- Formata para treinamento (input/output)
- Divide em treino/validaÃ§Ã£o/teste
- Salva em formato adequado para transformers

---

### 4. TREINAR MODELO TRANSFORMER

**NOVO SCRIPT NECESSÃRIO**: `93_treinar_modelo_enem.py`

```python
def treinar_modelo_enem():
    """
    Treina modelo transformer usando dados ENEM (2009-2025)
    
    OpÃ§Ãµes de modelo base:
    1. neuralmind/bert-base-portuguese-cased (BERT)
    2. neuralmind/bert-large-portuguese-cased (BERT Large)
    3. pierreguillou/gpt2-small-portuguese (GPT-2)
    4. SabiÃ¡-3 via fine-tuning (se API permitir)
    
    Metodologia:
    1. Carregar modelo base
    2. Preparar dataset (questÃµes ENEM)
    3. Fine-tuning com HuggingFace Transformers
    4. Avaliar em conjunto de validaÃ§Ã£o
    5. Salvar modelo treinado
    """
    pass
```

**AÃ§Ã£o**: Criar script que:
- Usa HuggingFace Transformers
- Carrega modelo base em portuguÃªs
- Faz fine-tuning com dados ENEM
- Avalia durante treinamento
- Salva modelo treinado

---

### 5. AVALIAR MODELO TREINADO

**NOVO SCRIPT NECESSÃRIO**: `94_avaliar_modelo_treinado.py`

```python
def avaliar_modelo_treinado():
    """
    Avalia modelo treinado em conjunto de teste
    
    MÃ©tricas:
    - AcurÃ¡cia geral
    - AcurÃ¡cia por Ã¡rea
    - AcurÃ¡cia por nÃ­vel de dificuldade (TRI)
    - AnÃ¡lise de erros
    """
    pass
```

---

## ğŸ“‹ PLANO DE IMPLEMENTAÃ‡ÃƒO

### FASE 1: PreparaÃ§Ã£o de Dados (1-2 dias)
- [ ] Verificar carregamento de TODOS os dados (2009-2025)
- [ ] Executar `04_gerar_embeddings.py` para todos os dados
- [ ] Validar que embeddings foram gerados corretamente

### FASE 2: Preparar Dataset (1 dia)
- [ ] Criar `92_preparar_dataset_treinamento.py`
- [ ] Formatar questÃµes para treinamento
- [ ] Dividir em treino/validaÃ§Ã£o/teste
- [ ] Validar estrutura do dataset

### FASE 3: Treinar Modelo (3-5 dias)
- [ ] Criar `93_treinar_modelo_enem.py`
- [ ] Escolher modelo base adequado
- [ ] Implementar fine-tuning
- [ ] Treinar modelo com todos os dados
- [ ] Salvar modelo treinado

### FASE 4: Avaliar Modelo (1-2 dias)
- [ ] Criar `94_avaliar_modelo_treinado.py`
- [ ] Avaliar em conjunto de teste
- [ ] Gerar relatÃ³rio de acurÃ¡cia
- [ ] Comparar com resultados anteriores

### FASE 5: IntegraÃ§Ã£o (1 dia)
- [ ] Integrar modelo treinado no sistema
- [ ] Substituir sistema de prompts por modelo treinado
- [ ] Testar end-to-end

---

## ğŸ”§ DEPENDÃŠNCIAS NECESSÃRIAS

```bash
pip install transformers torch
pip install datasets accelerate
pip install sentence-transformers
pip install scikit-learn
```

---

## ğŸ“Š ESTRUTURA ESPERADA

```
data/
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ enem_2009_completo.jsonl
â”‚   â”œâ”€â”€ enem_2010_completo.jsonl
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ enem_2025_completo.jsonl
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ embeddings_2009.npy
â”‚   â”œâ”€â”€ embeddings_2010.npy
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ embeddings_2025.npy
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”œâ”€â”€ validation.jsonl
â”‚   â””â”€â”€ test.jsonl
â””â”€â”€ models/
    â””â”€â”€ enem_bert_trained/
        â”œâ”€â”€ config.json
        â”œâ”€â”€ pytorch_model.bin
        â””â”€â”€ tokenizer files
```

---

## âš ï¸ IMPORTANTE

1. **NÃƒO usar dados fictÃ­cios** - apenas dados reais
2. **Validar cada etapa** antes de prosseguir
3. **Documentar todas as decisÃµes** de modelo/hiperparÃ¢metros
4. **Comparar resultados** com baseline (prompts simples)
5. **Ser transparente** sobre limitaÃ§Ãµes

---

## ğŸ¯ RESULTADO ESPERADO

ApÃ³s implementaÃ§Ã£o correta:
- Modelo NLP treinado com dados reais (2009-2025)
- AcurÃ¡cia medida em conjunto de teste real
- ComparaÃ§Ã£o honesta com outros mÃ©todos
- DocumentaÃ§Ã£o completa da metodologia

---

**Status**: ğŸ”´ CRÃTICO - ImplementaÃ§Ã£o necessÃ¡ria URGENTE

